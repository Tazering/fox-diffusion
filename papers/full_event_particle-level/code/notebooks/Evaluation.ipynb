{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c8acd-fb79-48a0-bb7c-62236d5aeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import h5py \n",
    "import numba\n",
    "\n",
    "# pip install lz4\n",
    "import lz4.frame\n",
    "\n",
    "# Optimal Transport\n",
    "# pip install POT\n",
    "import ot\n",
    "\n",
    "# https://github.com/scikit-hep/vector\n",
    "# pip install vector\n",
    "import vector\n",
    "\n",
    "# https://github.com/scikit-hep/mplhep\n",
    "# pip install mplhep\n",
    "import mplhep\n",
    "\n",
    "# Corner plots\n",
    "# pip install corner\n",
    "import corner\n",
    "\n",
    "# pip install dm-tree\n",
    "import tree\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats, special\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import orbax.checkpoint\n",
    "\n",
    "from lvd.config import Config\n",
    "from lvd.dataset import Dataset\n",
    "from lvd.trainers.lvd import create_trainer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter, ScalarFormatter\n",
    "\n",
    "import matplotlib as mpl\n",
    "import seaborn as sb\n",
    "\n",
    "jax.random.normal(jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3881c3b",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Edit the listed variables here to run different models. Link to the output log folder with the checkpoint and the dataset to test. Optionally compare against a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d10a21-e3a6-4eab-bf60-5ec88faac2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments\n",
    "# #######################################################################\n",
    "\n",
    "### Standard Model\n",
    "##################\n",
    "LOG_FOLDER = \"checkpoints/ttbar_particle_unfolding_weighted/version_22/\"\n",
    "CHECKPOINT = \"3300000\"\n",
    "TESTING_DATASET = \"dataset/processed/PP8_ttbar_particlelevel_SM.pt.partons.test.npz\"\n",
    "COMPARE_DATASET = None\n",
    "RUN_DIFFUSION = False\n",
    "\n",
    "### EFT vs SM\n",
    "#############\n",
    "# LOG_FOLDER = \"../checkpoints/ttbar_particle_unfolding_weighted/version_22/\"\n",
    "# CHECKPOINT = \"3300000\"\n",
    "# TESTING_DATASET = \"../dataset/processed/PP8_ttbar_particlelevel_EFT_ctg25_2M.pt.partons.test.npz\"\n",
    "# COMPARE_DATASET = \"../dataset/processed/PP8_ttbar_particlelevel_SM.pt.partons.test.npz\"\n",
    "# RUN_DIFFUSION = False\n",
    "\n",
    "### VAE SM (No Diffusion) vs Diffusion SM\n",
    "#########################################\n",
    "# LOG_FOLDER = \"../checkpoints/ttbar_particle_unfolding_weighted/version_22/\"\n",
    "# CHECKPOINT = \"3300000\"\n",
    "# TESTING_DATASET = \"../dataset/processed/PP8_ttbar_particlelevel_SM_VAE.pt.partons.test.npz\"\n",
    "# COMPARE_DATASET = \"../dataset/processed/PP8_ttbar_particlelevel_SM.pt.partons.test.npz\"\n",
    "# RUN_DIFFUSION = False\n",
    "\n",
    "guidance_scale = 0.0\n",
    "\n",
    "# Limit Noise Schedule gamma to particular values to avoid numerial issues.\n",
    "GAMMA_MAX = None\n",
    "GAMMA_MIN = None\n",
    "\n",
    "OUTPUT_FOLDER = f\"{LOG_FOLDER}/{CHECKPOINT}/{TESTING_DATASET.split('/')[-1]}\"\n",
    "COMPARE_FOLDER = f\"{LOG_FOLDER}/{CHECKPOINT}/{COMPARE_DATASET.split('/')[-1]}\" if COMPARE_DATASET is not None else None\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37da3b",
   "metadata": {},
   "source": [
    "### Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab16c12-4c4e-4101-8316-8d5cde46023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.load(f\"{LOG_FOLDER}/config.yaml\")\n",
    "\n",
    "testing_dataset = Dataset(TESTING_DATASET, include_squared_mass=config[\"training\"][\"consistency_loss_scale\"] > 0)\n",
    "example_batch = next(iter(testing_dataset.single_device_dataloader(batch_size=config.training.batch_size)))\n",
    "\n",
    "trainer = create_trainer(config)\n",
    "\n",
    "state = random_state = trainer.initialize(\n",
    "    jax.random.PRNGKey(0),\n",
    "    testing_dataset,\n",
    "    example_batch\n",
    ")\n",
    "\n",
    "checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "state = checkpointer.restore(f\"{LOG_FOLDER}/{CHECKPOINT}\", item=state)\n",
    "\n",
    "print(\"Number of Parameters\")\n",
    "np.sum(jax.tree_flatten(jax.tree_map(lambda x: np.prod(x.shape), state.lvd_state.params))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986413d4-858d-4041-a98b-71f25dc5841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially override the noise schedule limits. Useful for numerical issues.\n",
    "if GAMMA_MAX is not None:\n",
    "    state.lvd_state.params[\"gamma_limits\"][\"gamma_max\"] = jnp.array(GAMMA_MAX)\n",
    "\n",
    "if GAMMA_MIN is not None:\n",
    "    state.lvd_state.params[\"gamma_limits\"][\"gamma_min\"] = jnp.array(GAMMA_MIN)\n",
    "\n",
    "state.lvd_state.params[\"gamma_limits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed970516-ccdc-4497-8b18-5af8f222d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "model = trainer.model\n",
    "params = {**state.lvd_state.params, **state.gamma_state.params}\n",
    "apply_fn = partial(\n",
    "    model.apply, \n",
    "    {\"params\": params, \"normalization\": state.normalization},\n",
    ")\n",
    "\n",
    "network = trainer.model.bind(\n",
    "    {\"params\": params, \"normalization\": state.normalization}, \n",
    "    rngs=trainer.model.rngs(jax.random.PRNGKey(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21485ef3-06d9-4382-90ef-96bdb98cb64f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08dcb6f-628e-4151-868e-ebb16a61d784",
   "metadata": {},
   "source": [
    "## Noise Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e5b84a-ef67-4db0-a2d6-fac986982ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_particle_vectors = 11\n",
    "timesteps = jnp.linspace(0, 1, 1024)\n",
    "timesteps = jnp.broadcast_to(timesteps[:, None], (1024, max_particle_vectors))\n",
    "gamma = network.noise_schedule(timesteps, *network.gamma_limits())\n",
    "sigma = network.noise_schedule.sigma(timesteps, *network.gamma_limits())\n",
    "\n",
    "avg_timestep = (timesteps[1:] + timesteps[:-1]) / 2\n",
    "gamma_prime_symbolic = network.noise_schedule.prime(avg_timestep, *network.gamma_limits())[:, :, 0]\n",
    "gamma_prime_numeric = (gamma[1:, :, 0] - gamma[:-1, :, 0]) / (timesteps[1:] - timesteps[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc5394-65b1-482d-bf7b-29e63995c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sb.cubehelix_palette(n_colors=max_particle_vectors, start=.5, rot=-.5)\n",
    "cmap = [(1.0, 0.0, 0.0)] + cmap\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "for i, γ in enumerate(gamma[:, :, 0].T):\n",
    "    plt.plot(timesteps[:, 0], -γ, c=cmap[i], label=f\"Object {i}\" if i > 0 else \"Event\", linewidth=3);\n",
    "    \n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"$\\log{SNR}$\")\n",
    "plt.yticks([-10, -5, 0, 5, 10, 15])\n",
    "plt.legend(fontsize=\"x-small\")\n",
    "# plt.title(\"Learned Multi-Object Noise Schedule\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noise_schedule.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"noise_schedule.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = np.linspace(0, 1, 1024)\n",
    "timesteps = jnp.broadcast_to(timesteps[:, None], (timesteps.shape[0], 10))\n",
    "gamma = np.asarray(network.noise_schedule(timesteps, *network.gamma_limits())).astype(np.float64)\n",
    "\n",
    "log_alphas_cumprod = special.log_expit(-gamma)\n",
    "log_alphas = np.diff(log_alphas_cumprod, prepend=0, axis=0)\n",
    "betas = -np.expm1(log_alphas)[:, None, :]\n",
    "betas = jnp.array(betas.astype(np.float32))\n",
    "betas = betas.at[0].set(betas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sb.cubehelix_palette(n_colors=max_particle_vectors, start=.5, rot=-.5)\n",
    "cmap = [(1.0, 0.0, 0.0)] + cmap\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "for i, γ in enumerate(betas.reshape(timesteps.shape).T):\n",
    "    plt.plot(timesteps[:, 0], np.log(γ), c=cmap[i], label=f\"Object {i}\" if i > 0 else \"Event\", linewidth=3);\n",
    "    \n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"$\\\\log \\\\beta$\")\n",
    "plt.legend(fontsize=\"x-small\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"betas.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"betas.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bad2f-fe02-4704-83f1-cf1855184bed",
   "metadata": {},
   "source": [
    "## Perform Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "439a3ea7-1be6-401b-979e-62326b7682fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_STEPS = 1000\n",
    "GEN_VECTORS = 11\n",
    "NUM_OVERSAMPLES = 128\n",
    "BATCH_SIZE = config.training.batch_size // 2\n",
    "\n",
    "NUM_DEVICES = len(jax.devices())\n",
    "NUM_OVERSAMPLE_PER_DEVICE = max(NUM_OVERSAMPLES // NUM_DEVICES, 1)\n",
    "NUM_OVERSAMPLES = NUM_OVERSAMPLE_PER_DEVICE * NUM_DEVICES\n",
    "\n",
    "oversample_in_axes = (None, None, None, None, None, None, None, None, None, 0)\n",
    "oversample_static_argnums = (4, 5)\n",
    "\n",
    "oversample_ode = jax.pmap(\n",
    "    jax.vmap(trainer.generate.discrete, in_axes=oversample_in_axes),\n",
    "    in_axes=oversample_in_axes,\n",
    "    static_broadcasted_argnums=oversample_static_argnums,\n",
    ")\n",
    "\n",
    "oversample_reconstruct = jax.pmap(\n",
    "    jax.vmap(trainer.reconstruct, in_axes=(None, None, 0)),\n",
    "    in_axes=(None, None, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be7ccf15-a241-4d09-b383-96de6a71baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DIFFUSION:\n",
    "    outputs = []\n",
    "    key = jax.vmap(jax.random.split, in_axes=(0, None))(jax.random.split(state.seed, NUM_DEVICES), NUM_OVERSAMPLE_PER_DEVICE)\n",
    "    \n",
    "    def expand_oversample(arr):\n",
    "        return jnp.broadcast_to(arr[None], (NUM_OVERSAMPLES, *arr.shape))\n",
    "    \n",
    "    for batch in tqdm(testing_dataset.single_device_dataloader(batch_size=BATCH_SIZE), total=testing_dataset.num_events // BATCH_SIZE):\n",
    "        output, key = oversample_ode(\n",
    "            state,\n",
    "            batch.detector_vectors,\n",
    "            batch.detector_mask,\n",
    "            batch.detector_event,\n",
    "            GEN_VECTORS,\n",
    "            GEN_STEPS,\n",
    "            guidance_scale,\n",
    "            betas,\n",
    "            batch.particle_mask.sum(-1) + 1,\n",
    "            key\n",
    "        )\n",
    "     \n",
    "        outputs.append(jax.tree_map(np.array, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31416994-c87f-446c-959a-c6f39a2856fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_DIFFUSION:\n",
    "    def transponse_oversample(arr):\n",
    "        arr = arr.reshape(NUM_OVERSAMPLES, *arr.shape[2:])\n",
    "        return np.swapaxes(arr, 0, 1)\n",
    "    \n",
    "    output = jax.tree_map(lambda *x: np.concatenate(x, axis=2), *outputs)\n",
    "    output = jax.tree_map(transponse_oversample, output)\n",
    "    \n",
    "    with lz4.frame.open(f\"{OUTPUT_FOLDER}/outputs_oversample_{guidance_scale}.lz4\", mode='wb') as file:\n",
    "        pickle.dump(output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75444595-27bf-49ec-ad37-64c55127d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob(f\"{OUTPUT_FOLDER}/outputs_oversample_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bef48361-1cc1-4c01-be52-bbe610633e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(len(outputs))\n",
    "except NameError:\n",
    "    if os.path.exists(f\"{OUTPUT_FOLDER}/outputs_oversample_{guidance_scale}.lz4\"):\n",
    "        with lz4.frame.open(f\"{OUTPUT_FOLDER}/outputs_oversample_{guidance_scale}.lz4\", 'rb') as file:\n",
    "            output = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168075e-0608-4db6-ae4d-cd3dc67d1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_file = TESTING_DATASET.replace(\".test.npz\", \".preprocessing\")\n",
    "\n",
    "if os.path.exists(preprocessing_file):\n",
    "    print(preprocessing_file)\n",
    "    with open(preprocessing_file, 'rb') as file:\n",
    "        detector_vector_transform, detector_met_transform, particle_vector_transform, particle_met_transform = pickle.load(file)\n",
    "\n",
    "else:\n",
    "    print(\"No Preprocessing\")\n",
    "    detector_vector_transform = FunctionTransformer(lambda x: x, lambda x: x)\n",
    "    detector_met_transform = FunctionTransformer(lambda x: x, lambda x: x)\n",
    "    particle_vector_transform = FunctionTransformer(lambda x: x, lambda x: x)\n",
    "    particle_met_transform = FunctionTransformer(lambda x: x, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57841f5a-3149-419f-a1ea-30ea8985a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_particle(vectors, mask):\n",
    "    return mask[..., None] * particle_vector_transform.inverse_transform(vectors.reshape(-1, vectors.shape[-1])).reshape(vectors.shape)\n",
    "\n",
    "def transform_detector(vectors, mask):\n",
    "    return mask[..., None] * detector_vector_transform.inverse_transform(vectors.reshape(-1, vectors.shape[-1])).reshape(vectors.shape)\n",
    "\n",
    "def transform_particle_met(vectors):\n",
    "    return particle_met_transform.inverse_transform(vectors.reshape(-1, vectors.shape[-1])).reshape(vectors.shape)\n",
    "\n",
    "def transform_detector_met(vectors):\n",
    "    return detector_met_transform.inverse_transform(vectors.reshape(-1, vectors.shape[-1])).reshape(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff2dfb-f433-4826-b947-de9d07047add",
   "metadata": {},
   "source": [
    "## Extract Kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e4a2de-d189-4e7a-be7b-fbef04aaeab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vectors = transform_particle(output.vectors, output.mask).astype(np.float64)\n",
    "num_events = pred_vectors.shape[0]\n",
    "\n",
    "true_vectors = transform_particle(testing_dataset.particle_vectors, testing_dataset.particle_mask).astype(np.float64)[:num_events]\n",
    "true_detector = transform_detector(testing_dataset.detector_vectors, testing_dataset.detector_mask).astype(np.float64)[:num_events]\n",
    "\n",
    "pred_types = output.type_logits.argmax(-1)\n",
    "true_types = testing_dataset.particle_types[:num_events]\n",
    "detector_types = testing_dataset.detector_vectors[:, :,  -4:].argmax(-1)[:num_events]\n",
    "\n",
    "pred_mask = output.mask\n",
    "true_mask = testing_dataset.particle_mask[:num_events]\n",
    "detector_mask = testing_dataset.detector_mask[:num_events]\n",
    "\n",
    "pred_event = transform_particle_met(output.event).astype(np.float64)\n",
    "true_event = transform_particle_met(testing_dataset.particle_event).astype(np.float64)[:num_events]\n",
    "detector_event = transform_detector_met(testing_dataset.detector_event).astype(np.float64)[:num_events]\n",
    "\n",
    "pred_event = np.pad(pred_event, ((0, 0), (0, 0), (0, 1)), constant_values=0)\n",
    "true_event = np.pad(true_event, ((0, 0), (0, 1)), constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069b981-2f75-4644-bcf8-9e6175e8b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset):\n",
    "    values = dataset[:]\n",
    "    if values.dtype == np.float64:\n",
    "        values = values.astype(np.float32)\n",
    "    \n",
    "    if values.dtype == np.int32:\n",
    "        values = values.astype(np.int64)\n",
    "    \n",
    "    return values\n",
    "\n",
    "def read(file, level=0, path = [], verbose: bool = True):\n",
    "    if isinstance(file, h5py.Dataset):\n",
    "        return load_dataset(file)\n",
    "\n",
    "    database = {}\n",
    "    \n",
    "    iterator = file\n",
    "    if level == 1 and verbose:\n",
    "        iterator = tqdm(file, f\"Loading {path[-1]}\")\n",
    "        \n",
    "    for key in iterator:\n",
    "        database[key] = read(file[key], level + 1, path + [key], verbose=verbose)\n",
    "\n",
    "    return database\n",
    "\n",
    "base_dataset_name = TESTING_DATASET.split(\"/\")[-1].split(\".\")[0]\n",
    "base_dataset_type = TESTING_DATASET.split(\"/\")[-1].split(\".\")[-2]\n",
    "base_dataset_name = base_dataset_name.replace(\"_VAE\", \"\")\n",
    "base_dataset_name = base_dataset_name.replace(\"_ORACLE\", \"\")\n",
    "\n",
    "raw_dataset = glob(f\"../dataset/raw/{base_dataset_name}.h5\")[0]\n",
    "\n",
    "with h5py.File(raw_dataset) as file:\n",
    "    raw_dataset = read(file[\"partonlevel\"])\n",
    "    raw_detector = read(file[\"recolevel\"])\n",
    "    raw_particle_mask = np.concatenate((\n",
    "        file[\"particlelevel\"][\"electrons\"][\"mask\"][:],\n",
    "        file[\"particlelevel\"][\"muons\"][\"mask\"][:],\n",
    "        file[\"particlelevel\"][\"jets\"][\"mask\"][:]\n",
    "    ), axis=1)\n",
    "\n",
    "    raw_detector_mask = np.concatenate((\n",
    "        file[\"recolevel\"][\"electrons\"][\"mask\"][:],\n",
    "        file[\"recolevel\"][\"muons\"][\"mask\"][:],\n",
    "        file[\"recolevel\"][\"jets\"][\"mask\"][:]\n",
    "    ), axis=1)\n",
    "\n",
    "    mask = (raw_particle_mask.sum(1) > 0) & (raw_detector_mask.sum(1) > 0)\n",
    "\n",
    "    raw_dataset = jax.tree_map(lambda x: x[mask], raw_dataset)\n",
    "    raw_detector = jax.tree_map(lambda x: x[mask], raw_detector)\n",
    "    \n",
    "    if base_dataset_type == \"test\":\n",
    "        raw_dataset = jax.tree_map(lambda x: x[-testing_dataset.num_events:], raw_dataset)\n",
    "        raw_detector = jax.tree_map(lambda x: x[-testing_dataset.num_events:], raw_detector)\n",
    "\n",
    "raw_dataset = jax.tree_map(lambda x: x[:true_mask.shape[0]], raw_dataset)\n",
    "raw_detector = jax.tree_map(lambda x: x[:true_mask.shape[0]], raw_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7368adcc-1460-4665-8ed4-a07616926e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    type_wm = np.abs(np.concatenate((raw_dataset[\"Wm\"][\"d1\"][\"pid\"], raw_dataset[\"Wm\"][\"d2\"][\"pid\"]), axis=1))\n",
    "    type_wp = np.abs(np.concatenate((raw_dataset[\"Wp\"][\"d1\"][\"pid\"], raw_dataset[\"Wp\"][\"d2\"][\"pid\"]), axis=1))\n",
    "    wm_mask = ((type_wm <= 6) & (type_wm >= 1)).all(1) & ((type_wp <= 16) & (type_wp >= 11)).all(1)\n",
    "    wp_mask = ((type_wp <= 6) & (type_wp >= 1)).all(1) & ((type_wm <= 16) & (type_wm >= 11)).all(1)\n",
    "    topology_mask = (wp_mask ^ wm_mask)\n",
    "    \n",
    "    pred_vectors = pred_vectors[topology_mask]\n",
    "    true_vectors = true_vectors[topology_mask]\n",
    "    true_detector = true_detector[topology_mask]\n",
    "\n",
    "    pred_types = pred_types[topology_mask]\n",
    "    true_types = true_types[topology_mask]\n",
    "    detector_types = detector_types[topology_mask]\n",
    "\n",
    "    pred_mask = pred_mask[topology_mask]\n",
    "    true_mask = true_mask[topology_mask]\n",
    "    detector_mask = detector_mask[topology_mask]\n",
    "\n",
    "    pred_event = pred_event[topology_mask]\n",
    "    true_event = true_event[topology_mask]\n",
    "    detector_event = detector_event[topology_mask]\n",
    "\n",
    "    raw_dataset = jax.tree_map(lambda x: x[topology_mask], raw_dataset)\n",
    "    raw_detector = jax.tree_map(lambda x: x[topology_mask], raw_detector)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46442caa-f1d1-401f-9d19-26bfa441e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "KINEMATICS_DIMENSIONS = 5\n",
    "def extract_kinematics(vectors):\n",
    "    kinematics = vector.array({\n",
    "        \"px\": vectors[..., 0],\n",
    "        \"py\": vectors[..., 1],\n",
    "        \"pz\": vectors[..., 2],\n",
    "        # \"energy\": np.expm1(vectors[..., 3])\n",
    "        \"mass\": np.expm1(vectors[..., -1])\n",
    "    })\n",
    "\n",
    "    return vector.array({\n",
    "        \"pt\": kinematics.pt,\n",
    "        \"eta\": kinematics.eta,\n",
    "        \"phi\": kinematics.phi,\n",
    "        \"mass\": kinematics.mass,\n",
    "    })\n",
    "\n",
    "def extract_detector_kinematics(vectors):\n",
    "    return vector.array({\n",
    "        \"px\": vectors[..., 0],\n",
    "        \"py\": vectors[..., 1],\n",
    "        \"pz\": vectors[..., 2],\n",
    "        \"energy\": np.expm1(vectors[..., 3])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18f127cc-44ad-496d-9705-b7d447724ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_kinematics = extract_kinematics(pred_vectors)\n",
    "all_true_kinematics = extract_kinematics(true_vectors)\n",
    "all_detector_kinematics = extract_detector_kinematics(true_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93f6b374-327c-4cad-93d0-977beb859ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_function(vectors, mask, types):\n",
    "    pt_jet_mask = vectors.pt >= 25\n",
    "    eta_jet_mask = np.abs(vectors.eta) <= 4.9\n",
    "    mask = mask & pt_jet_mask & eta_jet_mask\n",
    "    types = types - (~mask)\n",
    "    \n",
    "    count_mask = ((types >= 0) & (types <= 1)).sum(-1) >= 4  # At least 4 hard jets\n",
    "    lepton_mask = (types > 1).sum(-1) == 1  # Exactly 1 lepton\n",
    "    b_mask = (types == 1).sum(-1) >= 2      # At least two of the jets are b-quarks\n",
    "    event_mask = count_mask & lepton_mask & b_mask\n",
    "\n",
    "    return event_mask[..., None] & mask\n",
    "\n",
    "raw_true_mask = true_mask\n",
    "raw_pred_mask = pred_mask\n",
    "raw_detector_mask = detector_mask\n",
    "\n",
    "true_mask = masking_function(all_true_kinematics, true_mask, true_types)\n",
    "pred_mask = masking_function(all_pred_kinematics, pred_mask, pred_types)\n",
    "detector_mask = masking_function(all_detector_kinematics, detector_mask, detector_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83911462-e91f-4b73-a458-97dc0071d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_met = np.expm1(pred_event[..., 0])\n",
    "pred_met_phi = np.arctan2(pred_event[..., 1], pred_event[..., 2])\n",
    "\n",
    "true_met = np.expm1(true_event[:, 0])\n",
    "true_met_phi = np.arctan2(true_event[:, 1], true_event[:, 2])\n",
    "\n",
    "detector_met = np.expm1(detector_event[:, 0])\n",
    "detector_met_phi = np.arctan2(detector_event[:, 1], detector_event[:, 2])\n",
    "\n",
    "idx = 3\n",
    "\n",
    "pred_hadronic_top = extract_kinematics(pred_event[..., idx:idx+KINEMATICS_DIMENSIONS])\n",
    "true_hadronic_top = extract_kinematics(true_event[..., idx:idx+KINEMATICS_DIMENSIONS])\n",
    "\n",
    "idx = idx + KINEMATICS_DIMENSIONS\n",
    "pred_leptonic_top = extract_kinematics(pred_event[..., idx:idx+KINEMATICS_DIMENSIONS])\n",
    "true_leptonic_top = extract_kinematics(true_event[..., idx:idx+KINEMATICS_DIMENSIONS])\n",
    "\n",
    "idx = idx + KINEMATICS_DIMENSIONS\n",
    "pred_neutrino = extract_kinematics(pred_event[..., idx:idx+KINEMATICS_DIMENSIONS])\n",
    "true_neutrino = extract_kinematics(true_event[..., idx:idx+KINEMATICS_DIMENSIONS])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f41c0-2f1f-4d69-acaf-5c5085dcfe51",
   "metadata": {},
   "source": [
    "# Unfolding Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f22b20",
   "metadata": {},
   "source": [
    "### Plotting Code\n",
    "\n",
    "The insanely complicated plotting code to make the plots in the paper. Here be dragons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82c4eb04-87c0-4726-b875-5caefe1b4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarFormatterForceFormat(ScalarFormatter):\n",
    "    def _set_format(self):  # Override function that finds format to use.\n",
    "        self.format = \"%1.1f\"  # Give format here\n",
    "\n",
    "    def __call__(self, x, pos=None):\n",
    "        if x == 0:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return super().__call__(x, pos)\n",
    "\n",
    "class ScalarFormatterForceFormatSimple(ScalarFormatter):\n",
    "    def __call__(self, x, pos=None):\n",
    "        if x == 0:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return super().__call__(x, pos)\n",
    "        \n",
    "def simple_hist(\n",
    "    true, \n",
    "    pred, \n",
    "    detector = None, \n",
    "    \n",
    "    true_mask = None,\n",
    "    pred_mask = None,\n",
    "    detector_mask = None,\n",
    "    \n",
    "    bins=128, \n",
    "    alpha=0.1, \n",
    "    beta=3, \n",
    "    ranges=None,\n",
    "    hist_yrange=None,\n",
    "    scatter_yrange=None,\n",
    "    log_scale = True,\n",
    "    xlabel = None,\n",
    "    save = None,\n",
    "    score = False,\n",
    "    density=True,\n",
    "    mask_names = None,\n",
    "    mask_name_location = None,\n",
    "    base_width=None,\n",
    "    compare=COMPARE_FOLDER,\n",
    "    fontsize=None\n",
    "):\n",
    "    if not isinstance(true_mask, list):\n",
    "        true_mask = [true_mask]\n",
    "    if not isinstance(pred_mask, list):\n",
    "        pred_mask = [pred_mask]\n",
    "    if not isinstance(detector_mask, list):\n",
    "        detector_mask = [detector_mask]\n",
    "\n",
    "    num_plots = len(true_mask)\n",
    "\n",
    "    if mask_names is None:\n",
    "        mask_names = [None] * num_plots\n",
    "\n",
    "    BASE_SIZE = 6\n",
    "    if base_width is None:\n",
    "        base_width = BASE_SIZE\n",
    "        \n",
    "    has_compare = compare is not None\n",
    "    true_color = \"b\" if not has_compare else \"m\"\n",
    "    unfolded_color = \"r\" if not has_compare else \"orange\"\n",
    "    detector_color = \"g\"\n",
    "\n",
    "    is_eft = \"EFT\" in OUTPUT_FOLDER\n",
    "    is_vae = \"VAE\" in OUTPUT_FOLDER\n",
    "    true_label = \"EFT Truth\" if is_eft else \"SM Truth\"\n",
    "    detector_label = \"EFT Detector\" if is_eft else \"SM Detector\"\n",
    "    unfolded_label = \"Unfolded\" if not has_compare else (\"VAE\" if is_vae else (\"EFT Unfolded\" if is_eft else \"SM Unfolded\"))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2, \n",
    "        ncols=num_plots, \n",
    "        height_ratios=(1.8, 1), \n",
    "        sharex=False, \n",
    "        squeeze=False, \n",
    "        figsize=(base_width * num_plots, BASE_SIZE)\n",
    "    )\n",
    "\n",
    "    base_true = true\n",
    "    base_pred = pred\n",
    "    base_detector = detector\n",
    "    \n",
    "    for plot_num, (true_mask, pred_mask, detector_mask, mask_name) in enumerate(zip(true_mask, pred_mask, detector_mask, mask_names)):\n",
    "        true = base_true\n",
    "        pred = base_pred\n",
    "        detector = base_detector\n",
    "        \n",
    "        ax1 = axes[0, plot_num]\n",
    "        ax2 = axes[1, plot_num]\n",
    "        \n",
    "        if true_mask is not None:\n",
    "            true = true[true_mask]\n",
    "    \n",
    "        if detector is not None and detector_mask is not None:\n",
    "            detector = detector[detector_mask]\n",
    "    \n",
    "        if ranges is None:\n",
    "            xmin = np.percentile(true, alpha)\n",
    "            xmax = np.percentile(true, 100.0 - alpha)\n",
    "        else:\n",
    "            xmin, xmax = ranges\n",
    "            \n",
    "        yt, x = np.histogram(true, bins=bins, range=(xmin, xmax), density=density)\n",
    "        if detector is not None:\n",
    "            yd, _  = np.histogram(detector, bins=bins, range=(xmin, xmax), density=density)            \n",
    "    \n",
    "        if score:\n",
    "            true_for_metrics = true[(true >= xmin) & (true <= xmax)]\n",
    "            \n",
    "        if pred.ndim > true.ndim:\n",
    "            yps = []\n",
    "            predicted_scores = []\n",
    "            \n",
    "            for i in range(pred.shape[1]):\n",
    "                current_pred = pred[:, i]\n",
    "                if pred_mask is not None:\n",
    "                    current_pred = current_pred[pred_mask[:, i]]\n",
    "                    \n",
    "                yp, _ = np.histogram(current_pred, bins=bins, range=(xmin, xmax), density=density)\n",
    "                yps.append(yp)\n",
    "    \n",
    "                if score:\n",
    "                    current_pred = current_pred[(current_pred >= xmin) & (current_pred <= xmax)]\n",
    "                    EM = ot.emd2_1d(true_for_metrics, current_pred, metric=\"euclidean\")\n",
    "                    ED = stats.energy_distance(true_for_metrics, current_pred)\n",
    "                    KL = np.sum(yt * np.log(yt / yp), where=(yt > 0) & (yp > 0))\n",
    "                    predicted_scores.append((EM, ED, KL))\n",
    "    \n",
    "            yps = np.array(yps)\n",
    "            predicted_scores = np.array(predicted_scores)\n",
    "            \n",
    "            ypm = yps.mean(0)\n",
    "            ypu = yps.max(0)\n",
    "            ypl = yps.min(0)\n",
    "    \n",
    "        x = (x[1:] + x[:-1]) / 2\n",
    "\n",
    "        lines = []\n",
    "        line_names = []\n",
    "        \n",
    "        l2, = ax1.plot(x, ypm, color=unfolded_color, linestyle='-', label=unfolded_label, linewidth=3)\n",
    "        ax1.fill_between(x, ypl, ypu, color=unfolded_color, alpha=0.2)\n",
    "        ax1.plot(x, ypl, color=unfolded_color, linestyle='--', alpha=0.4, linewidth=2)\n",
    "        ax1.plot(x, ypu, color=unfolded_color, linestyle='--', alpha=0.4, linewidth=2)\n",
    "        lines.append(l2)\n",
    "        line_names.append(unfolded_label)\n",
    "        \n",
    "        ax2.plot(x, np.log(ypm / yt), color=unfolded_color, linestyle='-', linewidth=3)\n",
    "        ax2.fill_between(x, np.log(ypl / yt), np.log(ypu / yt), color=unfolded_color, alpha=0.2)\n",
    "        ax2.plot(x, np.log(ypl / yt), color=unfolded_color, linestyle='--', alpha=0.4, linewidth=2)\n",
    "        ax2.plot(x, np.log(ypu / yt), color=unfolded_color, linestyle='--', alpha=0.4, linewidth=2)\n",
    "\n",
    "        l1, = ax1.plot(x, yt, color=true_color, linestyle='--', label=true_label, linewidth=4)\n",
    "        lines.append(l1)\n",
    "        line_names.append(true_label)\n",
    "\n",
    "        if detector is not None:\n",
    "            l3, = ax1.plot(x, yd, color=detector_color, linestyle=\":\", label=detector_label, linewidth=3)\n",
    "            ax2.plot(x, np.log(yd / yt), color=detector_color, linestyle=\":\", linewidth=3)\n",
    "            lines.append(l3)\n",
    "            line_names.append(detector_label)\n",
    "            \n",
    "        if compare is not None:\n",
    "            comp_data = np.load(f\"{compare}/{save}.{plot_num}.npz\")\n",
    "\n",
    "            comp_is_eft = \"EFT\" in compare\n",
    "            comp_true_label = \"EFT Truth\" if comp_is_eft else \"SM Truth\"\n",
    "            comp_detector_label = \"EFT Detector\" if comp_is_eft else \"SM Detector\"\n",
    "            comp_unfolded_label = \"Unfolded\" if not has_compare else (\"EFT Unfolded\" if comp_is_eft else \"SM Unfolded\")\n",
    "\n",
    "            l4, = ax1.plot(comp_data[\"x\"], comp_data[\"ypm\"], color='r', linestyle='-', label=comp_unfolded_label, linewidth=3)\n",
    "            ax2.plot(x, np.log(comp_data[\"ypm\"] / yt), color='r', linestyle='-', linewidth=3)\n",
    "            lines.append(l4)\n",
    "            line_names.append(comp_unfolded_label)\n",
    "            \n",
    "            if not is_vae:\n",
    "                l5, = ax1.plot(comp_data[\"x\"], comp_data[\"yt\"], color='b', linestyle='--', label=comp_true_label, linewidth=4)\n",
    "                ax2.plot(x, np.log(comp_data[\"yt\"] / yt), color='b', linestyle='--', linewidth=3)\n",
    "\n",
    "                lines.append(l5)\n",
    "                line_names.append(comp_true_label)\n",
    "        \n",
    "        ax2.hlines(0.0, xmin, xmax, linestyle='--', colors='m')\n",
    "\n",
    "        ax1.set_ylabel(\"Density\" if density else \"Count\")\n",
    "        ax2.set_ylabel(\"Log Ratio\")\n",
    "        ax1.set_xlim(xmin, xmax)\n",
    "        ax2.set_xlim(xmin, xmax)\n",
    "        \n",
    "        if log_scale:\n",
    "            ax1.set_yscale(\"log\")\n",
    "            ax1.set_ylabel(\"Density (Log Scale)\")\n",
    "                \n",
    "        if hist_yrange is not None:\n",
    "            ax1.set_ylim(*hist_yrange)\n",
    "    \n",
    "        if scatter_yrange is not None:\n",
    "            ax2.set_ylim(*scatter_yrange)\n",
    "\n",
    "        if has_compare:\n",
    "            if num_plots > 1:\n",
    "                plt.figlegend(lines, line_names, bbox_to_anchor=(0, 0, 0.95, 0.92), fontsize=\"x-small\" if fontsize is None else fontsize)\n",
    "            elif num_plots == 1:\n",
    "                ax1.legend(fontsize=\"small\" if fontsize is None else fontsize)\n",
    "\n",
    "        else:       \n",
    "            if num_plots > 1:\n",
    "                if detector is not None:\n",
    "                    plt.figlegend(lines, line_names, bbox_to_anchor=(0, 0, 0.95, 0.92), fontsize=\"small\" if fontsize is None else fontsize)\n",
    "            elif num_plots == 1:\n",
    "                    ax1.legend(fontsize=\"small\" if fontsize is None else fontsize)\n",
    "            \n",
    "        if plot_num == (num_plots - 1):\n",
    "            if xlabel is not None:\n",
    "                ax2.set_xlabel(xlabel)\n",
    "\n",
    "        if plot_num == 0:    \n",
    "            ax1.ticklabel_format(style=\"scientific\", scilimits=(0, 0), useMathText=True, axis=\"y\")\n",
    "            ax1.ticklabel_format(useMathText=True, axis=\"x\")\n",
    "            ax2.ticklabel_format(useMathText=True)\n",
    "            yfmt = ScalarFormatterForceFormat()\n",
    "            yfmt.set_powerlimits((0,0))\n",
    "            ax1.yaxis.set_major_formatter(yfmt)\n",
    "            ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:1.2f}' if bins == 10 else '{x:1.1f}'))\n",
    "            \n",
    "            fig.align_ylabels([ax1, ax2])\n",
    "\n",
    "            max_ylim = ax1.get_ylim()[1]            \n",
    "\n",
    "        else:\n",
    "            yfmt = ScalarFormatterForceFormatSimple()\n",
    "            ax2.xaxis.set_major_formatter(yfmt)\n",
    "            \n",
    "            ax1.set_ylabel(None)\n",
    "            ax2.set_ylabel(None)\n",
    "            \n",
    "            ax1.set_yticklabels([])\n",
    "            ax2.set_yticklabels([])\n",
    "\n",
    "        ax1.set_xlabel(None)\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_ylim(0, max_ylim)\n",
    "\n",
    "        if mask_name is not None:\n",
    "            x1, x2 = ax1.get_xlim()\n",
    "            xd = x2 - x1\n",
    "            xm = x1 + mask_name_location[0] * xd\n",
    "            \n",
    "            ax1.text(xm, mask_name_location[1] * ax1.get_ylim()[1], mask_name)\n",
    "\n",
    "        if save is not None:\n",
    "            np.savez(\n",
    "                f\"{OUTPUT_FOLDER}/{save}.{plot_num}.npz\", \n",
    "                x=x, yt=yt, ypm=ypm, ypl=ypl, ypu=ypu, yd=yd if detector is not None else None\n",
    "            )\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.1, wspace=0.0, right=0.96)\n",
    "        \n",
    "    if save is not None:\n",
    "        plt.savefig(f\"{OUTPUT_FOLDER}/{save}.png\", dpi=300)\n",
    "        plt.savefig(f\"{OUTPUT_FOLDER}/{save}.pdf\")\n",
    "        np.savez(f\"{OUTPUT_FOLDER}/{save}.npz\", x=x, yt=yt, ypm=ypm, ypl=ypl, ypu=ypu, yd=yd if detector is not None else None)\n",
    "        \n",
    "        if score:\n",
    "            with open(f\"{OUTPUT_FOLDER}/{save}.txt\", 'w') as score_file:\n",
    "                for metric in predicted_scores.T:\n",
    "                    print(f\"{metric.mean():.5f} [{metric.min():.5f}, {metric.max():.5f}]\", end=\"\\t\", file=score_file)\n",
    "                print(file=score_file)\n",
    "\n",
    "                if detector is not None:\n",
    "                    detector_for_metrics = detector[(detector >= xmin) & (detector <= xmax)]\n",
    "                    EM = ot.emd2_1d(true_for_metrics, detector_for_metrics, metric=\"euclidean\")\n",
    "                    ED = stats.energy_distance(true_for_metrics, detector_for_metrics)\n",
    "                    KL = np.sum(yt * np.log(yt / yd), where=(yt > 0) & (yd > 0))\n",
    "                    print(f\"{EM:.5f}\\t{ED:.5f}\\t{KL:.5f}\", file=score_file)\n",
    "                \n",
    "    return predicted_scores, fig, (ax1, ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd55b86",
   "metadata": {},
   "source": [
    "### Plotting Config\n",
    "Prepare for plotting. We're going to be using mplhep to use the ATLAS plotting style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1af679f4-dc68-42cb-9e69-9baf5a8216f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS = 64\n",
    "SCORE = False\n",
    "\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/event/\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/jets/\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/jets_split/\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/leptons/\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/observables/\", exist_ok=True)  \n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/assignment/\", exist_ok=True)\n",
    "sb.set_theme(context=\"paper\", style=\"whitegrid\", font_scale=2.4, rc={\"figure.figsize\": (6, 6)})\n",
    "mplhep.style.use(\"ATLAS\")\n",
    "mpl.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "mpl.rcParams[\"text.usetex\"] = True\n",
    "mpl.rcParams[\"axes.grid\"] = True\n",
    "mpl.rcParams[\"axes.grid.axis\"] = \"x\"\n",
    "mpl.rcParams[\"font.size\"] = 18.0\n",
    "mpl.rcParams[\"font.family\"] = \"Computer Modern\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86250a2e-d9ff-443e-89db-7df05ad98c61",
   "metadata": {},
   "source": [
    "## Hadronic Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cd1c1-f4fc-46c2-8fa6-a76580b169f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predicted_scores, *_ = simple_hist(\n",
    "    true_hadronic_top.pt, \n",
    "    pred_hadronic_top.pt, \n",
    "    bins=BINS, \n",
    "    ranges=(0, 500),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False, \n",
    "    xlabel=\"Parton Hadronic Top $P_\\\\mathrm{T}$ [GeV]\",\n",
    "    save=\"event/hadronic_top_pt\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_hadronic_top.eta, \n",
    "    pred_hadronic_top.eta, \n",
    "    bins=BINS, \n",
    "    ranges=(-2.5, 2.5),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False,\n",
    "    xlabel=\"Parton Hadronic Top $\\\\eta$\",\n",
    "    save=\"event/hadronic_top_eta\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_hadronic_top.phi, \n",
    "    pred_hadronic_top.phi, \n",
    "    bins=10, \n",
    "    ranges=(-3.1415, 3.1415),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    hist_yrange=(0, 0.2),\n",
    "    log_scale=False,\n",
    "    xlabel=\"Parton Hadronic Top $\\\\phi$\",\n",
    "    save=\"event/hadronic_top_phi\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_hadronic_top.mass, \n",
    "    pred_hadronic_top.mass, \n",
    "    bins=BINS, \n",
    "    alpha=1,\n",
    "    ranges=(50, 350),\n",
    "    scatter_yrange=(-2, 2),\n",
    "    log_scale=False,\n",
    "    xlabel=\"Parton Hadronic Top Mass [GeV]\",\n",
    "    save=\"event/hadronic_top_mass\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70115122-ad0d-44ba-bf4c-d7f99e156603",
   "metadata": {},
   "source": [
    "## Leptonic Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa63442-c610-4d32-a2f1-d2fe42843296",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    true_leptonic_top.pt, \n",
    "    pred_leptonic_top.pt, \n",
    "    bins=BINS, \n",
    "    ranges=(0, 500),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False, \n",
    "    xlabel=\"Parton Leptonic Top $p_\\\\mathrm{T}$ [GeV]\",\n",
    "    save=\"event/leptonic_top_pt\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_leptonic_top.eta, \n",
    "    pred_leptonic_top.eta, \n",
    "    bins=BINS, \n",
    "    ranges=(-2.5, 2.5),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False,\n",
    "    xlabel=\"Parton Leptonic Top $\\\\eta$\",\n",
    "    save=\"event/leptonic_top_eta\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_leptonic_top.phi, \n",
    "    pred_leptonic_top.phi, \n",
    "    bins=10, \n",
    "    ranges=(-3.1415, 3.1415),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    hist_yrange=(0, 0.2),\n",
    "    log_scale=False,\n",
    "    xlabel=\"Parton Leptonic Top $\\\\phi$\",\n",
    "    save=\"event/leptonic_top_phi\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_leptonic_top.mass, \n",
    "    pred_leptonic_top.mass, \n",
    "    bins=BINS, \n",
    "    alpha=1,\n",
    "    ranges=(50, 350),\n",
    "    scatter_yrange=(-2, 2),\n",
    "    log_scale=False,\n",
    "    xlabel=\"Parton Leptonic Top Mass [GeV]\",\n",
    "    save=\"event/leptonic_top_mass\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c93a4-a28c-406b-9b15-aedf2aa22f64",
   "metadata": {},
   "source": [
    "## Neutrino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea80fe-98cc-43fd-9acc-70562d460d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    true_neutrino.pt, \n",
    "    pred_neutrino.pt, \n",
    "    bins=BINS, \n",
    "    scatter_yrange=(-0.5, 0.5), \n",
    "    ranges=(0, 300),\n",
    "    log_scale=False, \n",
    "    xlabel=\"Neutrino $p_\\\\mathrm{T}$ [GeV]\",\n",
    "    save=\"event/neutrino_pt\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_neutrino.eta, \n",
    "    pred_neutrino.eta, \n",
    "    bins=BINS, \n",
    "    ranges=(-2.5, 2.5),\n",
    "    scatter_yrange=(-0.1, 0.1),\n",
    "    log_scale=False, \n",
    "    xlabel=\"Neutrino $\\\\eta$\",\n",
    "    save=\"event/neutrino_eta\"\n",
    ")\n",
    "\n",
    "simple_hist(\n",
    "    true_neutrino.phi, \n",
    "    pred_neutrino.phi, \n",
    "    bins=10, \n",
    "    ranges=(-3.1415, 3.1415),\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    hist_yrange=(0, 0.2),\n",
    "    log_scale=False, \n",
    "    xlabel=\"Neutrino $\\\\phi$\",\n",
    "    save=\"event/neutrino_phi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2360bb3-3d20-4a24-810c-c7f55586a92c",
   "metadata": {},
   "source": [
    "## MET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513388b-715b-4f8e-992a-f0e8b8921090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    true_met, \n",
    "    pred_met, \n",
    "    detector_met, \n",
    "    bins=BINS, \n",
    "    scatter_yrange=(-0.25, 0.25), \n",
    "    ranges=(0, 300),\n",
    "    log_scale=False, \n",
    "    xlabel=\"$E_\\\\mathrm{T}^\\\\mathrm{miss}$ [GeV]\",\n",
    "    save=\"event/met\",\n",
    "    score=SCORE\n",
    ");\n",
    "\n",
    "simple_hist(\n",
    "    true_met_phi, \n",
    "    pred_met_phi, \n",
    "    detector_met_phi, \n",
    "    bins=10, \n",
    "    scatter_yrange=(-0.02, 0.02), \n",
    "    ranges=(-3.1415, 3.1415),\n",
    "    hist_yrange=(0, 0.2),\n",
    "    log_scale=False, \n",
    "    xlabel=\"$\\\\phi^\\\\mathrm{miss}$\",\n",
    "    save=\"event/phi\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82571eef-f833-4c8a-bf4a-6dcd600bd71b",
   "metadata": {},
   "source": [
    "## Jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73020de-8776-48c6-967c-946db676550e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.pt, \n",
    "    all_pred_kinematics.pt, \n",
    "    all_detector_kinematics.pt,\n",
    "    pred_mask=pred_mask & (pred_types <= 1), \n",
    "    true_mask=true_mask & (true_types <= 1), \n",
    "    detector_mask=detector_mask & (detector_types <= 1),\n",
    "    bins=BINS,\n",
    "    ranges=(0, 400),\n",
    "    scatter_yrange=(-0.2, 0.2),\n",
    "    log_scale=False,\n",
    "    xlabel=\"$p_\\\\mathrm{T}^\\\\mathrm{jet}$ [GeV]\",\n",
    "    save=\"jets/pt\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b51592-b730-48d7-a97c-b5e32d63d1b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.pt, \n",
    "    all_pred_kinematics.pt, \n",
    "    all_detector_kinematics.pt,\n",
    "    pred_mask=[\n",
    "        pred_mask & (pred_types <= 1) & (pred_mask.sum(-1, keepdims=True) <= 5), \n",
    "        pred_mask & (pred_types <= 1) & (pred_mask.sum(-1, keepdims=True) == 6), \n",
    "        pred_mask & (pred_types <= 1) & (pred_mask.sum(-1, keepdims=True) >= 7)\n",
    "    ], \n",
    "    true_mask=[\n",
    "        true_mask & (true_types <= 1) & (true_mask.sum(-1, keepdims=True) <= 5), \n",
    "        true_mask & (true_types <= 1) & (true_mask.sum(-1, keepdims=True) == 6), \n",
    "        true_mask & (true_types <= 1) & (true_mask.sum(-1, keepdims=True) >= 7)\n",
    "    ], \n",
    "    detector_mask=[\n",
    "        detector_mask & (detector_types <= 1) & (detector_mask.sum(-1, keepdims=True) <= 5), \n",
    "        detector_mask & (detector_types <= 1) & (detector_mask.sum(-1, keepdims=True) == 6), \n",
    "        detector_mask & (detector_types <= 1) & (detector_mask.sum(-1, keepdims=True) >= 7)\n",
    "    ], \n",
    "    bins=BINS,\n",
    "    ranges=(0, 400),\n",
    "    scatter_yrange=(-0.2, 0.2),\n",
    "    hist_yrange=(0, 3.0e-2),\n",
    "    log_scale=False,\n",
    "    xlabel=\"$p_\\\\mathrm{T}^\\\\mathrm{jet}$ [GeV]\",\n",
    "    save=\"jets_split/pt_by_n\",\n",
    "    score=SCORE,\n",
    "    mask_names=[\"$N_{jets} \\\\leq 4$\", \"$N_{jets} = 5$\", \"$N_{jets} \\\\geq 6$\"],\n",
    "    mask_name_location=[0.15, 0.85],\n",
    "    base_width=5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce131b94-0bba-4748-9b0b-11f2b89d009d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.eta, \n",
    "    all_pred_kinematics.eta, \n",
    "    all_detector_kinematics.eta,\n",
    "    pred_mask=pred_mask & (pred_types <= 1), \n",
    "    true_mask=true_mask & (true_types <= 1), \n",
    "    detector_mask=detector_mask & (detector_types <= 1),\n",
    "    ranges=(-2.5, 2.5),\n",
    "    bins=BINS,\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False,\n",
    "    xlabel=\"$\\\\eta^\\\\mathrm{jet}$\",\n",
    "    save=\"jets/eta\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f597ec-777a-44ee-9cb9-cf6c58582843",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.phi, \n",
    "    all_pred_kinematics.phi, \n",
    "    all_detector_kinematics.phi,\n",
    "    pred_mask=pred_mask & (pred_types <= 1), \n",
    "    true_mask=true_mask & (true_types <= 1), \n",
    "    detector_mask=detector_mask & (detector_types <= 1),\n",
    "    ranges=(-3.1415, 3.1415),\n",
    "    hist_yrange=(0, 0.2),\n",
    "    bins=10,\n",
    "    scatter_yrange=(-0.02, 0.02),\n",
    "    log_scale=False,\n",
    "    xlabel=\"$\\\\phi^\\\\mathrm{jet}$\",\n",
    "    save=\"jets/phi\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc345d4e-2ddd-490e-b9c2-1926af45a545",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.mass, \n",
    "    all_pred_kinematics.mass, \n",
    "    all_detector_kinematics.mass,\n",
    "    pred_mask=pred_mask & (pred_types <= 1), \n",
    "    true_mask=true_mask & (true_types <= 1), \n",
    "    detector_mask=detector_mask & (detector_types <= 1),\n",
    "    ranges=(0, 60),\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$m^\\\\mathrm{jet}$ [GeV]\",\n",
    "    save=\"jets/mass\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647edc9e-f6a2-4042-b40f-4cf56b72ccd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.mass, \n",
    "    all_pred_kinematics.mass, \n",
    "    all_detector_kinematics.mass,\n",
    "    pred_mask=[\n",
    "        pred_mask & (pred_types <= 1) & (pred_mask.sum(-1, keepdims=True) <= 5), \n",
    "        pred_mask & (pred_types <= 1) & (pred_mask.sum(-1, keepdims=True) == 6), \n",
    "        pred_mask & (pred_types <= 1) & (pred_mask.sum(-1, keepdims=True) >= 7)\n",
    "    ], \n",
    "    true_mask=[\n",
    "        true_mask & (true_types <= 1) & (true_mask.sum(-1, keepdims=True) <= 5), \n",
    "        true_mask & (true_types <= 1) & (true_mask.sum(-1, keepdims=True) == 6), \n",
    "        true_mask & (true_types <= 1) & (true_mask.sum(-1, keepdims=True) >= 7)\n",
    "    ], \n",
    "    detector_mask=[\n",
    "        detector_mask & (detector_types <= 1) & (detector_mask.sum(-1, keepdims=True) <= 5), \n",
    "        detector_mask & (detector_types <= 1) & (detector_mask.sum(-1, keepdims=True) == 6), \n",
    "        detector_mask & (detector_types <= 1) & (detector_mask.sum(-1, keepdims=True) >= 7)\n",
    "    ], \n",
    "    ranges=(0, 50),\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$m^\\\\mathrm{jet}$ [GeV]\",\n",
    "    save=\"jets_split/mass_by_n\",\n",
    "    score=SCORE,\n",
    "    mask_names=[\"$N_{jets} \\\\leq 4$\", \"$N_{jets} = 5$\", \"$N_{jets} \\\\geq 6$\"],\n",
    "    mask_name_location=[0.3, 0.8],\n",
    "    base_width=5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab073fc4-9f17-4029-9cda-ea50ee60fbb4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "delta = np.abs(pred_mask.sum(-1, keepdims=True)[:, 0] - detector_mask.sum(-1, keepdims=True))\n",
    "\n",
    "simple_hist(\n",
    "    all_true_kinematics.mass, \n",
    "    all_pred_kinematics.mass[:, 0:1], \n",
    "    all_detector_kinematics.mass,\n",
    "    pred_mask=[\n",
    "        pred_mask[:, 0:1] & (pred_types[:, 0:1] <= 1) & (delta[:, None] == 0), \n",
    "        pred_mask[:, 0:1] & (pred_types[:, 0:1] <= 1) & (delta[:, None] == 1), \n",
    "        pred_mask[:, 0:1] & (pred_types[:, 0:1] <= 1) & (delta[:, None] >= 2)\n",
    "    ], \n",
    "    true_mask=[\n",
    "        true_mask & (true_types <= 1) & (delta == 0), \n",
    "        true_mask & (true_types <= 1) & (delta == 1), \n",
    "        true_mask & (true_types <= 1) & (delta >= 2)\n",
    "    ], \n",
    "    detector_mask=[\n",
    "        detector_mask & (detector_types <= 1) & (delta == 0), \n",
    "        detector_mask & (detector_types <= 1) & (delta == 1),\n",
    "        detector_mask & (detector_types <= 1) & (delta >= 2)\n",
    "    ], \n",
    "    ranges=(0, 50),\n",
    "    scatter_yrange=(-1, 1),\n",
    "    hist_yrange=(0, 1.2e-1),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$m^\\\\mathrm{jet}$  [GeV]\",\n",
    "    save=\"jets_split/mass_by_delta_n\",\n",
    "    score=SCORE,\n",
    "    mask_names=[\"$|\\\\Delta N| = 0$\", \"$|\\\\Delta N| = 1$\", \"$|\\\\Delta N| \\geq 2$\"],\n",
    "    mask_name_location=[0.3, 0.8],\n",
    "    base_width=5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12d140-9832-4038-a87c-eecd61e3be67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.energy, \n",
    "    all_pred_kinematics.energy, \n",
    "    all_detector_kinematics.energy,\n",
    "    pred_mask=pred_mask & (pred_types <= 1), \n",
    "    true_mask=true_mask & (true_types <= 1), \n",
    "    detector_mask=detector_mask & (detector_types <= 1),\n",
    "    ranges=(0, 800),\n",
    "    scatter_yrange=(-0.2, 0.2),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$E^\\\\mathrm{jet}$ [GeV]\",\n",
    "    save=\"jets/energy\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dba5cd-5fe1-4ce2-81a3-0465a06d7604",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.pz, \n",
    "    all_pred_kinematics.pz, \n",
    "    all_detector_kinematics.pz,\n",
    "    pred_mask=pred_mask & (pred_types <= 1), \n",
    "    true_mask=true_mask & (true_types <= 1), \n",
    "    detector_mask=detector_mask & (detector_types <= 1),\n",
    "    # ranges=(0, 800),\n",
    "    alpha=1.0,\n",
    "    bins=BINS,\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False,\n",
    "    xlabel= \"$p_z^\\\\mathrm{jet}$ [GeV]\",\n",
    "    save=\"jets/pz\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8c7d1-93f2-4925-a84e-d0d94704849b",
   "metadata": {},
   "source": [
    "## Leptons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea832c-1c50-4edf-af82-45bc5e723771",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.pt, \n",
    "    all_pred_kinematics.pt, \n",
    "    all_detector_kinematics.pt,\n",
    "    pred_mask=pred_mask & (pred_types > 1), \n",
    "    true_mask=true_mask & (true_types > 1), \n",
    "    detector_mask=detector_mask & (detector_types > 1),\n",
    "    ranges=(0, 200),\n",
    "    bins=BINS,\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False,\n",
    "    xlabel=\"$p_\\\\mathrm{T}^\\\\mathrm{lep}$ [GeV]\",\n",
    "    save=\"leptons/pt\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc2728-c54c-467f-84e9-397b71900ebd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.eta, \n",
    "    all_pred_kinematics.eta, \n",
    "    all_detector_kinematics.eta,\n",
    "    pred_mask=pred_mask & (pred_types > 1), \n",
    "    true_mask=true_mask & (true_types > 1), \n",
    "    detector_mask=detector_mask & (detector_types > 1),\n",
    "    ranges=(-2.5, 2.5),\n",
    "    bins=BINS,\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    log_scale=False,\n",
    "    xlabel=\"$\\\\eta^\\\\mathrm{lep}$\",\n",
    "    save=\"leptons/eta\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab626e-066f-46b8-9f03-8d3195637a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.phi, \n",
    "    all_pred_kinematics.phi, \n",
    "    all_detector_kinematics.phi,\n",
    "    pred_mask=pred_mask & (pred_types > 1), \n",
    "    true_mask=true_mask & (true_types > 1), \n",
    "    detector_mask=detector_mask & (detector_types > 1),\n",
    "    ranges=(-3.1415, 3.1415),\n",
    "    scatter_yrange=(-0.02, 0.02),\n",
    "    hist_yrange=(0, 0.2),\n",
    "    bins=10,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$\\\\phi^\\\\mathrm{lep}$\",\n",
    "    save=\"leptons/phi\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360cd6b7-7f8c-4210-a9a9-5a58fa0fe29a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.mass, \n",
    "    all_pred_kinematics.mass, \n",
    "    all_detector_kinematics.mass,\n",
    "    pred_mask=pred_mask & (pred_types > 1), \n",
    "    true_mask=true_mask & (true_types > 1), \n",
    "    detector_mask=detector_mask & (detector_types > 1),\n",
    "    ranges=(0, 1),\n",
    "    scatter_yrange=(-2, 2),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$m^\\\\mathrm{lep}$ [GeV]\",\n",
    "    save=\"leptons/mass\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e826bb-71e9-45b0-aa1b-6dd3186f6a91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.energy, \n",
    "    all_pred_kinematics.energy, \n",
    "    all_detector_kinematics.energy,\n",
    "    pred_mask=pred_mask & (pred_types > 1), \n",
    "    true_mask=true_mask & (true_types > 1), \n",
    "    detector_mask=detector_mask & (detector_types > 1),\n",
    "    ranges=(0, 800),\n",
    "    scatter_yrange=(-0.2, 0.2),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$E^\\\\mathrm{lep}$ [GeV]\",\n",
    "    save=\"leptons/energy\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cda48f-42f9-481b-9f5c-6b59de15a338",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    all_true_kinematics.pz, \n",
    "    all_pred_kinematics.pz, \n",
    "    all_detector_kinematics.pz,\n",
    "    pred_mask=pred_mask & (pred_types > 1), \n",
    "    true_mask=true_mask & (true_types > 1), \n",
    "    detector_mask=detector_mask & (detector_types > 1),\n",
    "    # ranges=(0, 800),\n",
    "    scatter_yrange=(-0.2, 0.2),\n",
    "    bins=BINS,\n",
    "    log_scale=False,\n",
    "    xlabel=\"$p_z^\\\\mathrm{lep}$ [GeV]\",\n",
    "    save=\"leptons/pz\",\n",
    "    score=SCORE\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738b465-5ebb-4cb8-891d-31d52dcbfeb0",
   "metadata": {},
   "source": [
    "# Observable Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840aad9f-0c65-491b-abe8-e6fdf9d2d1dd",
   "metadata": {},
   "source": [
    "## Matching Algorithms\n",
    "\n",
    "Several different matching algorithms implemented:\n",
    "- Oracle - Based on distance from the partons\n",
    "- Pseudo-Top - First estimate and match leptonic b and then hadronic b.\n",
    "- Pseudo-Top with neutrino - Like before but use neutrino kinematics predictions instead of quadratic solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54e37fb9-b1b6-43c6-b2a9-fe97424f4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.vectorize\n",
    "def pid_to_type(arr):\n",
    "    arr = np.abs(arr)\n",
    "    if arr == 5:\n",
    "        return 1\n",
    "    elif arr == 11:\n",
    "        return 2\n",
    "    elif arr == 13:\n",
    "        return 3\n",
    "    elif arr == 15:\n",
    "        return 4\n",
    "    elif arr == 12:\n",
    "        return 5\n",
    "    elif arr == 14:\n",
    "        return 5\n",
    "    elif arr== 16:\n",
    "        return 5\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def parton_to_vector(parton):\n",
    "    return vector.array({\n",
    "        \"energy\": parton[\"e\"],\n",
    "        \"eta\": parton[\"eta\"],\n",
    "        \"phi\": parton[\"phi\"],\n",
    "        \"pt\": parton[\"pt\"]\n",
    "    }), pid_to_type(parton[\"pid\"])\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def remove_indices(weights, indices, new_value):\n",
    "    for i in numba.prange(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            weights[i, j, indices[i]] += new_value\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def count_unique(array, max_value):\n",
    "    counts = np.zeros((array.shape[0], max_value), dtype=np.int64)\n",
    "    for i in numba.prange(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            counts[i, array[i, j]] += 1\n",
    "\n",
    "    return counts\n",
    "    \n",
    "def oracle_match(dataset, particle_kinematics, particle_types, particle_mask):\n",
    "    pid_m = np.abs(dataset[\"partonlevel\"][\"Wm\"][\"d2\"][\"pid\"].ravel())\n",
    "    anti_top_is_leptonic = pid_m > 10\n",
    "    anti_top_is_hadronic = pid_m <= 10\n",
    "    \n",
    "    lb = tree.map_structure(\n",
    "        lambda x, y: np.where(anti_top_is_leptonic, x.ravel(), y.ravel()), \n",
    "        dataset[\"partonlevel\"][\"antitop\"][\"d1\"], \n",
    "        dataset[\"partonlevel\"][\"top\"][\"d1\"]\n",
    "    )\n",
    "    \n",
    "    ll = tree.map_structure(\n",
    "        lambda x, y: np.where(anti_top_is_leptonic, x.ravel(), y.ravel()), \n",
    "        dataset[\"partonlevel\"][\"Wm\"][\"d1\"], \n",
    "        dataset[\"partonlevel\"][\"Wp\"][\"d1\"]\n",
    "    )\n",
    "    \n",
    "    ln = tree.map_structure(\n",
    "        lambda x, y: np.where(anti_top_is_leptonic, x.ravel(), y.ravel()), \n",
    "        dataset[\"partonlevel\"][\"Wm\"][\"d2\"], \n",
    "        dataset[\"partonlevel\"][\"Wp\"][\"d2\"]\n",
    "    )\n",
    "    \n",
    "    hb = tree.map_structure(\n",
    "        lambda x, y: np.where(anti_top_is_hadronic, x.ravel(), y.ravel()), \n",
    "        dataset[\"partonlevel\"][\"antitop\"][\"d1\"], \n",
    "        dataset[\"partonlevel\"][\"top\"][\"d1\"]\n",
    "    )\n",
    "    \n",
    "    hq1 = tree.map_structure(\n",
    "        lambda x, y: np.where(anti_top_is_hadronic, x.ravel(), y.ravel()), \n",
    "        dataset[\"partonlevel\"][\"Wm\"][\"d1\"], \n",
    "        dataset[\"partonlevel\"][\"Wp\"][\"d1\"]\n",
    "    )\n",
    "    \n",
    "    hq2 = tree.map_structure(\n",
    "        lambda x, y: np.where(anti_top_is_hadronic, x.ravel(), y.ravel()), \n",
    "        dataset[\"partonlevel\"][\"Wm\"][\"d2\"], \n",
    "        dataset[\"partonlevel\"][\"Wp\"][\"d2\"]\n",
    "    )\n",
    "    \n",
    "    hb, hbt = parton_to_vector(hb)\n",
    "    hq1, hq1t = parton_to_vector(hq1)\n",
    "    hq2, hq2t = parton_to_vector(hq2)\n",
    "    \n",
    "    lb, lbt = parton_to_vector(lb)\n",
    "    ll, llt = parton_to_vector(ll)\n",
    "    ln, lnt = parton_to_vector(ln)\n",
    "    \n",
    "    partons = [hb, hq1, hq2, lb, ll, ln]\n",
    "    parton_types = np.array([hbt, hq1t, hq2t, lbt, llt, lnt])\n",
    "\n",
    "    pt_jet_mask = particle_kinematics.pt > 25\n",
    "    eta_jet_mask = np.abs(particle_kinematics.eta) < 4.9\n",
    "    particle_mask = particle_mask & pt_jet_mask & eta_jet_mask\n",
    "    particle_types = (particle_mask * particle_types) - (~particle_mask)\n",
    "    \n",
    "    tau_mask = ~(parton_types == 4).any(0)\n",
    "    neutrino_mask = (parton_types == 5).sum(0) == 1\n",
    "    count_mask = ((particle_types >= 0) & (particle_types <= 1)).sum(1) >= 4  # At least 4 hard jets\n",
    "    lepton_mask = (particle_types > 1).sum(1) == 1  # Exactly 1 lepton\n",
    "    b_mask = (particle_types == 1).sum(1) >= 2      # At least two of the jets are b-quarks\n",
    "    \n",
    "    event_mask = tau_mask & count_mask & lepton_mask & b_mask & neutrino_mask\n",
    "    \n",
    "    weights = []\n",
    "    for p, pt in zip(partons, parton_types):\n",
    "        weight = particle_kinematics.deltaR(p[:, None])\n",
    "        weight += np.where(particle_types == pt[:, None], 0.0, np.inf)\n",
    "        weight += np.where(particle_mask, 0.0, np.inf)\n",
    "        weights.append(weight)\n",
    "    \n",
    "    weights = np.stack(weights, axis=1)\n",
    "    weights[:, 3] += particle_kinematics.deltaR(partons[4][:, None])\n",
    "    \n",
    "    MAX_OFFSET = 10 * np.max(weights, initial=0, where=np.isfinite(weights))\n",
    "    weights = np.where(np.isfinite(weights), weights, MAX_OFFSET)\n",
    "\n",
    "    llm = np.argmin(weights[:, 4] , axis=-1)\n",
    "    remove_indices(weights, llm, MAX_OFFSET)\n",
    "    \n",
    "    lbm = np.argmin(weights[:, 3] , axis=-1)\n",
    "    remove_indices(weights, lbm, MAX_OFFSET)\n",
    "    \n",
    "    hbm = np.argmin(weights[:, 0] , axis=-1)\n",
    "    remove_indices(weights, hbm, MAX_OFFSET)\n",
    "    \n",
    "    hq1m = np.argmin(weights[:, 1] , axis=-1)\n",
    "    remove_indices(weights, hq1m, MAX_OFFSET)\n",
    "    \n",
    "    hq2m = np.argmin(weights[:, 2] , axis=-1)\n",
    "    remove_indices(weights, hq2m, MAX_OFFSET)\n",
    "\n",
    "    dummy_indices = np.arange(particle_kinematics.shape[0])\n",
    "    llp = particle_kinematics[dummy_indices, llm]\n",
    "    lbp = particle_kinematics[dummy_indices, lbm]\n",
    "    hbp = particle_kinematics[dummy_indices, hbm]\n",
    "    hq1p = particle_kinematics[dummy_indices, hq1m]\n",
    "    hq2p = particle_kinematics[dummy_indices, hq2m]\n",
    "    lnp = ln\n",
    "    \n",
    "    ttbar = vector.array({\n",
    "        \"px\": np.stack((hbp.px, hq1p.px, hq2p.px, lbp.px, llp.px, lnp.px), axis=1),\n",
    "        \"py\": np.stack((hbp.py, hq1p.py, hq2p.py, lbp.py, llp.py, lnp.py), axis=1),\n",
    "        \"pz\": np.stack((hbp.pz, hq1p.pz, hq2p.pz, lbp.pz, llp.pz, lnp.pz), axis=1),\n",
    "        \"mass\": np.stack((hbp.mass, hq1p.mass, hq2p.mass, lbp.mass, llp.mass, lnp.mass), axis=1),\n",
    "    })\n",
    "\n",
    "    ttbar_mask = np.stack((\n",
    "        particle_mask[dummy_indices, hbm],\n",
    "        particle_mask[dummy_indices, hq1m],\n",
    "        particle_mask[dummy_indices, hq2m],\n",
    "        particle_mask[dummy_indices, lbm],\n",
    "        particle_mask[dummy_indices, llm],\n",
    "        np.isfinite(lnp.pz)\n",
    "    ), axis=1)\n",
    "\n",
    "    ttbar_mask = ttbar_mask & event_mask[:, None]\n",
    "    \n",
    "    return ttbar, ttbar_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ea527eb-b4b2-4984-aaca-62f4b8edbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_match_b_quark(vectors, types, mask, met, met_phi, hard_mask: bool = True, pre_mask = None):\n",
    "    # Apply Premask computed from global decision such as pass rate\n",
    "    if pre_mask is not None:    \n",
    "        pre_mask = pre_mask[:vectors.shape[0]]\n",
    "        vectors = vectors[:pre_mask.shape[0]][pre_mask]\n",
    "        mask = mask[:pre_mask.shape[0]][pre_mask]\n",
    "        types = types[:pre_mask.shape[0]][pre_mask]\n",
    "        met = met[:pre_mask.shape[0]][pre_mask]\n",
    "        met_phi = met_phi[:pre_mask.shape[0]][pre_mask]\n",
    "\n",
    "    # Limit events to those that pass pre-selection\n",
    "    pt_jet_mask = vectors.pt > 25\n",
    "    eta_jet_mask = np.abs(vectors.eta) < 4.9\n",
    "    mask = mask & pt_jet_mask & eta_jet_mask\n",
    "    types = (mask * types) - (~mask)\n",
    "    \n",
    "    count_mask = ((types >= 0) & (types <= 1)).sum(1) >= 4  # At least 4 hard jets\n",
    "    lepton_mask = (types > 1).sum(-1) == 1  # Exactly 1 lepton\n",
    "    b_mask = (types == 1).sum(-1) >= 2      # At least two of the jets are b-quarks\n",
    "    event_mask = count_mask & lepton_mask & b_mask\n",
    "    print(event_mask.mean())\n",
    "    print((event_mask & (mask.sum(-1) == 5)).sum())\n",
    "        \n",
    "    if hard_mask:\n",
    "        vectors = vectors[event_mask]\n",
    "        mask = mask[event_mask]\n",
    "        types = types[event_mask]\n",
    "        met = met[event_mask]\n",
    "        met_phi = met_phi[event_mask]\n",
    "    \n",
    "    DUMMY_INDEX = np.arange(vectors.shape[0])\n",
    "\n",
    "    # Gather the highest pt leptons\n",
    "    lepton_indices = (types > 1).argmax(1)\n",
    "    lepton = vectors[DUMMY_INDEX, lepton_indices]\n",
    "    lepton_type = types[DUMMY_INDEX, lepton_indices]\n",
    "    \n",
    "    nu_pt = met\n",
    "    nu_px = met * np.cos(met_phi)\n",
    "    nu_py = met * np.sin(met_phi)\n",
    "    \n",
    "    lepton_mass = np.where(lepton_type == 2, 5.109989461e-4, 0.1056583745)\n",
    "    W_mass = 80.379\n",
    "    \n",
    "    alpha = (W_mass ** 2) - (lepton_mass ** 2) + 2 * (lepton.px * nu_px + lepton.py * nu_py)\n",
    "\n",
    "    a = lepton.pz ** 2 - lepton.energy ** 2\n",
    "    b = alpha * lepton.pz\n",
    "    c = ( (alpha ** 2) / 4) - (lepton.energy ** 2) * (nu_pt ** 2)\n",
    "\n",
    "    nu_pz = np.stack((\n",
    "        (-b + np.sqrt(b ** 2 - 4 * a * c)) / (2 * a),\n",
    "        (-b - np.sqrt(b ** 2 - 4 * a * c)) / (2 * a)\n",
    "    ), axis=-1)\n",
    "\n",
    "    nu_pz = np.nan_to_num(nu_pz, nan=np.inf)\n",
    "    nu_pz = nu_pz[DUMMY_INDEX, np.abs(nu_pz).argmin(-1)]\n",
    "\n",
    "    neutrino = vector.array({\n",
    "        \"px\": nu_px,\n",
    "        \"py\": nu_py,\n",
    "        \"pz\": nu_pz,\n",
    "        \"mass\": np.zeros_like(nu_px)\n",
    "    })[:, None]\n",
    "    \n",
    "    lepton = lepton[:, None]\n",
    "    lepton_distance = vectors.deltaR(lepton) + np.where(types == 1, 0.0, np.inf)\n",
    "    leptonic_b_indices = lepton_distance.argmin(1)\n",
    "    leptonic_b = vectors[DUMMY_INDEX, leptonic_b_indices][:, None]\n",
    "\n",
    "    hadronic_indices = np.copy(np.broadcast_to(np.arange(vectors.shape[1])[None, :], vectors.shape))\n",
    "    hadronic_indices[DUMMY_INDEX, lepton_indices] += vectors.shape[1]\n",
    "    hadronic_indices[DUMMY_INDEX, leptonic_b_indices] += vectors.shape[1]\n",
    "\n",
    "    hadronic_b_indices = np.copy(hadronic_indices)\n",
    "    hadronic_q_indices = np.copy(hadronic_b_indices)\n",
    "\n",
    "    hadronic_b_indices[types != 1] += vectors.shape[1]\n",
    "    hadronic_q_indices[types != 0] += vectors.shape[1]\n",
    "    \n",
    "    hadronic_b_indices = np.sort(hadronic_b_indices, axis=1)[:, :1]\n",
    "    hadronic_q_indices = np.sort(hadronic_q_indices, axis=1)[:, :2]\n",
    "    hadronic_indices = np.concatenate((hadronic_b_indices, hadronic_q_indices), axis=1)\n",
    "    hadronic_indices[hadronic_indices >= vectors.shape[1]] = -1\n",
    "    hadronic_top = vectors[DUMMY_INDEX[:, None], hadronic_indices]\n",
    "    \n",
    "    ttbar = vector.array({\n",
    "        \"px\": np.concatenate((hadronic_top.px, leptonic_b.px, lepton.px, neutrino.px), axis=1),\n",
    "        \"py\": np.concatenate((hadronic_top.py, leptonic_b.py, lepton.py, neutrino.py), axis=1),\n",
    "        \"pz\": np.concatenate((hadronic_top.pz, leptonic_b.pz, lepton.pz, neutrino.pz), axis=1),\n",
    "        \"mass\": np.concatenate((hadronic_top.mass, leptonic_b.mass, lepton.mass, neutrino.mass), axis=1)\n",
    "    })\n",
    "\n",
    "    print(hadronic_indices)\n",
    "    ttbar_mask = np.concatenate((\n",
    "        mask[DUMMY_INDEX[:, None], hadronic_indices],\n",
    "        mask[DUMMY_INDEX, leptonic_b_indices][:, None],\n",
    "        mask[DUMMY_INDEX, lepton_indices][:, None],\n",
    "        np.isfinite(neutrino.pz)\n",
    "    ), axis=1)\n",
    "\n",
    "    if not hard_mask:\n",
    "        ttbar_mask = ttbar_mask & event_mask[:, None]\n",
    "\n",
    "    return ttbar, ttbar_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3482ff1d-cc3b-406e-b817-abc2beecafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_match_b_quark_with_neutrino(vectors, types, mask, event, hard_mask: bool = True, pre_mask = None):\n",
    "    if pre_mask is not None:    \n",
    "        pre_mask = pre_mask[:vectors.shape[0]]\n",
    "        vectors = vectors[:pre_mask.shape[0]][pre_mask]\n",
    "        mask = mask[:pre_mask.shape[0]][pre_mask]\n",
    "        types = types[:pre_mask.shape[0]][pre_mask]\n",
    "        event = event[:pre_mask.shape[0]][pre_mask]\n",
    "    \n",
    "    count_mask = mask.sum(1) >= 5\n",
    "    lepton_mask = (types > 1).sum(1) >= 1\n",
    "    b_mask = (types == 1).sum(1) >= 2\n",
    "    event_mask = count_mask & lepton_mask & b_mask\n",
    "    print(event_mask.mean())\n",
    "\n",
    "    if hard_mask:\n",
    "        vectors = vectors[event_mask]\n",
    "        mask = mask[event_mask]\n",
    "        types = types[event_mask]\n",
    "        event = event[event_mask]\n",
    "    \n",
    "    DUMMY_INDEX = np.arange(vectors.shape[0])\n",
    "    \n",
    "    lepton_indices = (types > 1).argmax(1)\n",
    "    lepton = vectors[DUMMY_INDEX, lepton_indices]\n",
    "    lepton_type = types[DUMMY_INDEX, lepton_indices]\n",
    "\n",
    "    neutrino = vector.array({\n",
    "        \"px\": event[..., -4],\n",
    "        \"py\": event[..., -3],\n",
    "        \"pz\": event[..., -2],\n",
    "        \"mass\": np.zeros_like(event[..., -2])\n",
    "    })[:, None]\n",
    "\n",
    "    lepton = lepton[:, None]\n",
    "    lepton_distance = vectors.deltaR(lepton) + np.where(types == 1, 0.0, np.inf) + np.where(mask, 0.0, np.inf)\n",
    "    leptonic_b_indices = lepton_distance.argmin(1)\n",
    "    leptonic_b = vectors[DUMMY_INDEX, leptonic_b_indices][:, None]\n",
    "\n",
    "    hadronic_indices = np.copy(np.broadcast_to(np.arange(vectors.shape[1])[None, :], vectors.shape))\n",
    "    hadronic_indices[DUMMY_INDEX, lepton_indices] += vectors.shape[1]\n",
    "    hadronic_indices[DUMMY_INDEX, leptonic_b_indices] += vectors.shape[1]\n",
    "\n",
    "    hadronic_b_indices = np.copy(hadronic_indices)\n",
    "    hadronic_q_indices = np.copy(hadronic_b_indices)\n",
    "\n",
    "    hadronic_b_indices[types != 1] += vectors.shape[1]\n",
    "    hadronic_q_indices[types != 0] += vectors.shape[1]\n",
    "    \n",
    "    hadronic_b_indices = np.sort(hadronic_b_indices, axis=1)[:, :1]\n",
    "    hadronic_q_indices = np.sort(hadronic_q_indices, axis=1)[:, :2]\n",
    "    hadronic_indices = np.concatenate((hadronic_b_indices, hadronic_q_indices), axis=1)\n",
    "    hadronic_indices[hadronic_indices >= vectors.shape[1]] = -1\n",
    "    hadronic_top = vectors[DUMMY_INDEX[:, None], hadronic_indices]\n",
    "    \n",
    "    ttbar = vector.array({\n",
    "        \"px\": np.concatenate((hadronic_top.px, leptonic_b.px, lepton.px, neutrino.px), axis=1),\n",
    "        \"py\": np.concatenate((hadronic_top.py, leptonic_b.py, lepton.py, neutrino.py), axis=1),\n",
    "        \"pz\": np.concatenate((hadronic_top.pz, leptonic_b.pz, lepton.pz, neutrino.pz), axis=1),\n",
    "        \"mass\": np.concatenate((hadronic_top.mass, leptonic_b.mass, lepton.mass, neutrino.mass), axis=1)\n",
    "    })\n",
    "    \n",
    "    ttbar_mask = np.concatenate((\n",
    "        mask[DUMMY_INDEX[:, None], hadronic_indices],\n",
    "        mask[DUMMY_INDEX, leptonic_b_indices][:, None],\n",
    "        mask[DUMMY_INDEX, lepton_indices][:, None],\n",
    "        np.isfinite(neutrino.pz)\n",
    "        # np.zeros_like(mask[DUMMY_INDEX, lepton_indices][:, None])\n",
    "    ), axis=1)\n",
    "\n",
    "    if not hard_mask:\n",
    "        ttbar_mask = ttbar_mask & event_mask[:, None]\n",
    "\n",
    "    return ttbar, ttbar_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1547b2-07e1-4058-b19b-c9b14498267e",
   "metadata": {},
   "source": [
    "## Match Datasets\n",
    "\n",
    "Perform matching algorithm on unfolded datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4453b308-212b-4973-8de8-3b2d3129effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def permutation_index(array, permutations):\n",
    "    output = np.empty_like(array)\n",
    "\n",
    "    for i in numba.prange(array.shape[0]):\n",
    "        output[i] = array[i, permutations[i]]\n",
    "\n",
    "    return output\n",
    "    \n",
    "a, b, c = pred_mask.shape\n",
    "pred_order = np.where(pred_mask.reshape(-1, c), all_pred_kinematics.pt.reshape(-1, c), -np.inf)\n",
    "pred_permutations = np.argsort(pred_order, axis=-1)[..., ::-1]\n",
    "\n",
    "sorted_all_pred_kinematics_pt = permutation_index(all_pred_kinematics.pt.reshape(-1, c), pred_permutations).reshape(a, b, c)\n",
    "sorted_all_pred_kinematics_eta = permutation_index(all_pred_kinematics.eta.reshape(-1, c), pred_permutations).reshape(a, b, c)\n",
    "sorted_all_pred_kinematics_phi = permutation_index(all_pred_kinematics.phi.reshape(-1, c), pred_permutations).reshape(a, b, c)\n",
    "sorted_all_pred_kinematics_mass = permutation_index(all_pred_kinematics.mass.reshape(-1, c), pred_permutations).reshape(a, b, c)\n",
    "\n",
    "sorted_all_pred_kinematics = vector.array({\n",
    "    \"pt\": sorted_all_pred_kinematics_pt,\n",
    "    \"eta\": sorted_all_pred_kinematics_eta,\n",
    "    \"phi\": sorted_all_pred_kinematics_phi,\n",
    "    \"mass\": sorted_all_pred_kinematics_mass\n",
    "})\n",
    "\n",
    "del sorted_all_pred_kinematics_pt\n",
    "del sorted_all_pred_kinematics_eta\n",
    "del sorted_all_pred_kinematics_phi\n",
    "del sorted_all_pred_kinematics_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b091ad5-239b-4a4f-ba5b-c03038b8facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "POST_OVERSAMPLE = 128\n",
    "PRE_MASK_PERCENTAGE = 0.0\n",
    "\n",
    "pred_count_mask = pred_mask.sum(-1) >= 5\n",
    "pred_lepton_mask = (pred_types > 1).sum(-1) >= 1\n",
    "pred_b_mask = (pred_types == 1).sum(-1) >= 2\n",
    "pred_event_mask = pred_count_mask & pred_lepton_mask & pred_b_mask\n",
    "\n",
    "detector_count_mask = detector_mask.sum(-1) >= 5\n",
    "detector_lepton_mask = (detector_types > 1).sum(-1) >= 1\n",
    "detector_b_mask = (detector_types == 1).sum(-1) >= 2\n",
    "detector_event_mask = detector_count_mask & detector_lepton_mask & detector_b_mask\n",
    "\n",
    "pred_event_pre_mask = pred_event_mask.mean(-1) >= PRE_MASK_PERCENTAGE\n",
    "\n",
    "truth_event_pre_mask = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4eef5-8636-47c4-b094-c542b0f55606",
   "metadata": {},
   "source": [
    "### Pseudo-Top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362c0c0-6609-4806-85dc-1f6d6b548af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_matchings = [\n",
    "    auto_match_b_quark(sorted_all_pred_kinematics[:, i], pred_types[:, i], pred_mask[:, i], pred_met[:, i], pred_met_phi[:, i], hard_mask=False, pre_mask=pred_event_pre_mask)\n",
    "    for i in range(min(sorted_all_pred_kinematics.shape[1], POST_OVERSAMPLE))\n",
    "]\n",
    "\n",
    "pred_ttbar = vector.array({\n",
    "    \"px\": np.stack([p[0].px for p in pred_matchings]),\n",
    "    \"py\": np.stack([p[0].py for p in pred_matchings]),\n",
    "    \"pz\": np.stack([p[0].pz for p in pred_matchings]),\n",
    "    \"energy\": np.stack([p[0].energy for p in pred_matchings]),\n",
    "})\n",
    "\n",
    "pred_ttbar_mask = np.stack([p[1] for p in pred_matchings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c3ca2-b047-407f-9f09-91ea005e29fa",
   "metadata": {},
   "source": [
    "## Observable Definitions\n",
    "\n",
    "Define all of our interesting observables in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a16e950-1249-41c8-af14-b10f8555a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hadronic_top_mass(pred_ttbar, pred_ttbar_mask):\n",
    "    t_mass = pred_ttbar[..., :3].sum(-1).mass\n",
    "    t_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "\n",
    "    return t_mass, t_mask\n",
    "\n",
    "def leptonic_top_mass(pred_ttbar, pred_ttbar_mask):\n",
    "    t_mass = pred_ttbar[..., 3:].sum(-1).mass\n",
    "    t_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "\n",
    "    return t_mass, t_mask\n",
    "\n",
    "def both_top_mass(pred_ttbar, pred_ttbar_mask):\n",
    "    t1_mass = pred_ttbar[..., :3].sum(-1).mass\n",
    "    t2_mass = pred_ttbar[..., 3:].sum(-1).mass\n",
    "    \n",
    "    t1_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "    t2_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "    \n",
    "    t_mass = np.concatenate((t1_mass, t2_mass), axis=-1)\n",
    "    t_mask = np.concatenate((t1_mask, t2_mask), axis=-1)\n",
    "\n",
    "    return t_mass, t_mask\n",
    "\n",
    "def ttbar_mass(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar.sum(-1).mass\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def ttbar_pt(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar.sum(-1).pt\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def ttbar_eta(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar.sum(-1).eta\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def ttbar_phi(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar.sum(-1).phi\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def ttbar_energy(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar.sum(-1).energy\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def ttbar_y(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = np.abs(pred_ttbar.sum(-1).rapidity)\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def thad_pt(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., :3].sum(-1).pt\n",
    "    ttbar_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "\n",
    "def thad_eta(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., :3].sum(-1).eta\n",
    "    ttbar_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def thad_phi(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., :3].sum(-1).phi\n",
    "    ttbar_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def thad_energy(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., :3].sum(-1).energy\n",
    "    ttbar_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def tlep_pt(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., 3:].sum(-1).pt\n",
    "    ttbar_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "\n",
    "def tlep_eta(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., 3:].sum(-1).eta\n",
    "    ttbar_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def tlep_phi(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., 3:].sum(-1).phi\n",
    "    ttbar_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def tlep_energy(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = pred_ttbar[..., 3:].sum(-1).energy\n",
    "    ttbar_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def thad_y(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = np.abs(pred_ttbar[..., :3].sum(-1).rapidity)\n",
    "    ttbar_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def tlep_y(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mass = np.abs(pred_ttbar[..., 3:].sum(-1).rapidity)\n",
    "    ttbar_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "\n",
    "    return ttbar_mass, ttbar_mask\n",
    "\n",
    "def t_pt(pred_ttbar, pred_ttbar_mask):\n",
    "    t1_mass = pred_ttbar[..., :3].sum(-1).pt\n",
    "    t2_mass = pred_ttbar[..., 3:].sum(-1).pt\n",
    "    \n",
    "    t1_mask = pred_ttbar_mask[..., :3].all(-1)\n",
    "    t2_mask = pred_ttbar_mask[..., 3:].all(-1)\n",
    "    \n",
    "    t_mass = np.concatenate((t1_mass, t2_mass), axis=-1)\n",
    "    t_mask = np.concatenate((t1_mask, t2_mask), axis=-1)\n",
    "\n",
    "    return t_mass, t_mask\n",
    "\n",
    "def ttbar_chi(pred_ttbar, pred_ttbar_mask):\n",
    "    y1 = pred_ttbar[..., :3].sum(-1).rapidity\n",
    "    y2 = pred_ttbar[..., 3:].sum(-1).rapidity\n",
    "    y_star = 0.5 * (y1 - y2)\n",
    "    \n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return np.exp(2 * np.abs(y_star)), ttbar_mask\n",
    "\n",
    "def ttbar_y_boost(pred_ttbar, pred_ttbar_mask):\n",
    "    y1 = pred_ttbar[..., :3].sum(-1).rapidity\n",
    "    y2 = pred_ttbar[..., 3:].sum(-1).rapidity\n",
    "    y_boost = 0.5 * (y1 + y2)\n",
    "\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return np.abs(y_boost), ttbar_mask\n",
    "\n",
    "def top_angle(pred_ttbar, pred_ttbar_mask):\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    t1 = pred_ttbar[..., :3].sum(-1)\n",
    "    t2 = pred_ttbar[..., 3:].sum(-1)\n",
    "\n",
    "    delta_angle = t1.deltaangle(t2)\n",
    "\n",
    "    return delta_angle, ttbar_mask\n",
    "\n",
    "def ttbar_Ht(pred_ttbar, pred_ttbar_mask):\n",
    "    pt = pred_ttbar[..., :3].sum(-1).pt + pred_ttbar[..., 3:].sum(-1).pt\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return pt, ttbar_mask\n",
    "\n",
    "def both_b_mass(pred_ttbar, pred_ttbar_mask):\n",
    "    t1_mass = pred_ttbar[..., :1].sum(-1).mass\n",
    "    t2_mass = pred_ttbar[..., 3:4].sum(-1).mass\n",
    "    \n",
    "    t1_mask = pred_ttbar_mask[..., :1].all(-1)\n",
    "    t2_mask = pred_ttbar_mask[..., 3:4].all(-1)\n",
    "    \n",
    "    t_mass = np.concatenate((t1_mass, t2_mass), axis=-1)\n",
    "    t_mask = np.concatenate((t1_mask, t2_mask), axis=-1)\n",
    "    \n",
    "    return t_mass, t_mask\n",
    "\n",
    "\n",
    "def both_W_mass(pred_ttbar, pred_ttbar_mask):\n",
    "    t1_mass = pred_ttbar[..., 1:3].sum(-1).mass\n",
    "    t2_mass = pred_ttbar[..., 4:].sum(-1).mass\n",
    "    \n",
    "    t1_mask = pred_ttbar_mask[..., 1:3].all(-1)\n",
    "    t2_mask = pred_ttbar_mask[..., 4:].all(-1)\n",
    "    \n",
    "    t_mass = np.concatenate((t1_mass, t2_mass), axis=-1)\n",
    "    t_mask = np.concatenate((t1_mask, t2_mask), axis=-1)\n",
    "    \n",
    "    return t_mass, t_mask\n",
    "\n",
    "def pt_out_had(pred_ttbar, pred_ttbar_mask):\n",
    "    top_had = pred_ttbar[..., :3].sum(-1)\n",
    "    top_lep = pred_ttbar[..., 3:].sum(-1)\n",
    "    top_had = np.stack((top_had.px, top_had.py, top_had.pz), axis=-1)\n",
    "    top_lep = np.stack((top_lep.px, top_lep.py, top_lep.pz), axis=-1)\n",
    "    ez = np.array([0, 0, 1])\n",
    "    while ez.ndim < top_lep.ndim:\n",
    "        ez = np.expand_dims(ez, 0)\n",
    "    top_lep = np.cross(top_lep, ez)\n",
    "    top_lep = top_lep / np.linalg.norm(top_lep, axis=-1, keepdims=True)\n",
    "\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return np.abs((top_had * top_lep).sum(-1)), ttbar_mask\n",
    "\n",
    "def pt_out_lep(pred_ttbar, pred_ttbar_mask):\n",
    "    top_had = pred_ttbar[..., :3].sum(-1)\n",
    "    top_lep = pred_ttbar[..., 3:].sum(-1)\n",
    "    top_had = np.stack((top_had.px, top_had.py, top_had.pz), axis=-1)\n",
    "    top_lep = np.stack((top_lep.px, top_lep.py, top_lep.pz), axis=-1)\n",
    "    \n",
    "    ez = np.array([0, 0, 1])\n",
    "    while ez.ndim < top_lep.ndim:\n",
    "        ez = np.expand_dims(ez, 0)\n",
    "        \n",
    "    top_had = np.cross(top_had, ez)\n",
    "    top_had = top_had / np.linalg.norm(top_had, axis=-1, keepdims=True)\n",
    "\n",
    "    ttbar_mask = pred_ttbar_mask.all(-1)\n",
    "\n",
    "    return np.abs((top_had * top_lep).sum(-1)), ttbar_mask\n",
    "\n",
    "\n",
    "observables = [\n",
    "    hadronic_top_mass, \n",
    "    leptonic_top_mass, \n",
    "    both_top_mass,\n",
    "    \n",
    "    ttbar_mass, \n",
    "    ttbar_pt, \n",
    "    ttbar_eta, \n",
    "    ttbar_phi, \n",
    "    ttbar_energy, \n",
    "    ttbar_y, \n",
    "    \n",
    "    thad_pt, \n",
    "    thad_eta, \n",
    "    thad_phi, \n",
    "    thad_energy, \n",
    "    thad_y, \n",
    "    \n",
    "    tlep_pt, \n",
    "    tlep_eta, \n",
    "    tlep_phi, \n",
    "    tlep_energy, \n",
    "    tlep_y, \n",
    "    \n",
    "    t_pt, \n",
    "    ttbar_chi, \n",
    "    ttbar_y_boost, \n",
    "    top_angle, \n",
    "    ttbar_Ht, \n",
    "    both_b_mass, \n",
    "    both_W_mass, \n",
    "    pt_out_had, \n",
    "    pt_out_lep\n",
    "]\n",
    "observables = {func.__name__: func for func in observables}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b2d6c",
   "metadata": {},
   "source": [
    "## Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0c1067c-1f7a-49d4-bb4f-c1b6940422db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORACLE_MATCHING = False\n",
    "\n",
    "OBSERVABLES = [\n",
    "    (\"both_top_mass\", \"$m^\\\\mathrm{top}$ [GeV]\", 50, 350, None, None),\n",
    "    (\"hadronic_top_mass\", \"$m^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", 50, 350, None, None),\n",
    "    (\"leptonic_top_mass\", \"$m^{\\\\mathrm{top},\\\\mathrm{lep}}$ [GeV]\", 50, 350, None, None),\n",
    "    (\"both_W_mass\", \"$m^W$ [GeV]\", 25, 175, None, None),\n",
    "    (\"both_b_mass\", \"$m^b$ [GeV]\", None, None, None, None),\n",
    "    \n",
    "    (\"pt_out_had\", \"$p^{\\\\mathrm{top},\\\\mathrm{had}}_{\\\\mathrm{Out}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"pt_out_lep\", \"$p^{\\\\mathrm{top},\\\\mathrm{lep}}_{\\\\mathrm{Out}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    \n",
    "    (\"ttbar_mass\", \"$m^{t \\\\bar{t}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"ttbar_pt\", \"$p_T^{t \\\\bar{t}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"ttbar_eta\", \"$\\\\eta^{t \\\\bar{t}}$\", -2.5, 2.5, -0.5, 0.5),\n",
    "    (\"ttbar_phi\", \"$\\\\phi^{t \\\\bar{t}}$\", -3.1415, 3.1415, -0.1, 0.1),\n",
    "    (\"ttbar_energy\", \"$E^{t \\\\bar{t}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"ttbar_y\", \"$y^{t \\\\bar{t}}$\", None, None, -0.5, 0.5),\n",
    "    \n",
    "    (\"thad_pt\", \"$p_T^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"thad_eta\", \"$\\\\eta^{\\\\mathrm{top},\\\\mathrm{had}}$\", -2.5, 2.5, -0.5, 0.5),\n",
    "    (\"thad_phi\", \"$\\\\phi^{\\\\mathrm{top},\\\\mathrm{had}}$\", -3.1415, 3.1415, -0.1, 0.1),\n",
    "    (\"thad_energy\", \"$E^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"thad_y\", \"$y^{\\\\mathrm{top},\\\\mathrm{had}}$\", None, None, -0.5, 0.5),\n",
    "\n",
    "    (\"tlep_pt\", \"$p_T^{\\\\mathrm{top},\\\\mathrm{lep}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"tlep_eta\", \"$\\\\eta^{\\\\mathrm{top},\\\\mathrm{lep}}$\", -2.5, 2.5, -0.5, 0.5),\n",
    "    (\"tlep_phi\", \"$\\\\phi^{\\\\mathrm{top},\\\\mathrm{lep}}$\", -3.1415, 3.1415, -0.1, 0.1),\n",
    "    (\"tlep_energy\", \"$E^{\\\\mathrm{top}, \\\\mathrm{lep}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"tlep_y\", \"$y^{\\\\mathrm{top},\\\\mathrm{lep}}$\", None, None, -0.5, 0.5),\n",
    "    \n",
    "    (\"t_pt\", \"$p_\\\\mathrm{T}^\\\\mathrm{top}$\", None, None, None, None),\n",
    "    (\"ttbar_chi\", \"$\\\\chi^{t \\\\bar{t}}$\", None, None, None, None),\n",
    "    (\"ttbar_y_boost\", \"$y_{boost}^{t \\\\bar{t}}$\", None, None, -0.5, 0.5),\n",
    "    (\"top_angle\", \"$\\\\Delta \\\\phi^{t, \\\\bar{t}}$\", None, None, -0.5, 0.5),\n",
    "    (\"ttbar_Ht\", \"$H_\\\\mathrm{T}^{t \\\\bar{t}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2f5b1-dc74-473b-a8e9-1b76644110d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ttbar, true_ttbar_mask = auto_match_b_quark(all_true_kinematics, true_types, true_mask, true_met, true_met_phi, pre_mask=truth_event_pre_mask, hard_mask=True)\n",
    "detector_ttbar, detector_ttbar_mask = auto_match_b_quark(all_detector_kinematics, detector_types, detector_mask, detector_met, detector_met_phi, hard_mask=True)\n",
    "\n",
    "assignment_out_dir = f\"assignment_oracle\" if ORACLE_MATCHING else f\"assignment\"\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/{assignment_out_dir}\", exist_ok=True)\n",
    "for name, fancy_name, xmin, xmax, rmin, rmax in OBSERVABLES:\n",
    "    observable = observables[name]\n",
    "\n",
    "    pred_observable, pred_observable_mask = observable(pred_ttbar, pred_ttbar_mask)\n",
    "    true_observable, true_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    detector_observable, detector_observable_mask = observable(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "    ranges = (xmin, xmax) if xmin is not None else None\n",
    "    \n",
    "    simple_hist(\n",
    "        true_observable,\n",
    "        pred_observable.T,\n",
    "        detector_observable,\n",
    "        true_observable_mask,\n",
    "        pred_observable_mask.T,\n",
    "        detector_observable_mask,\n",
    "        log_scale=False,\n",
    "        scatter_yrange=(-1 if rmin is None else rmin, 1 if rmax is None else rmax),\n",
    "        bins=BINS,\n",
    "        xlabel=fancy_name,\n",
    "        hist_yrange=(0, 0.2) if \"phi\" in name else None,\n",
    "        save=f\"{assignment_out_dir}/{name}\",\n",
    "        ranges=ranges,\n",
    "        score=SCORE,\n",
    "        fontsize=\"x-small\" if ((\"eta\" in name) or (\"top_angle\" in name)) else \"small\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11bc87-16c4-452f-b4bc-16f58882c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ttbar, true_ttbar_mask = auto_match_b_quark(all_true_kinematics, true_types, true_mask, true_met, true_met_phi, pre_mask=truth_event_pre_mask, hard_mask=False)\n",
    "detector_ttbar, detector_ttbar_mask = auto_match_b_quark(all_detector_kinematics, detector_types, detector_mask, detector_met, detector_met_phi, hard_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35940559-ce46-430a-b80e-b51f9f82fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_observable, pred_observable_mask = ttbar_mass(pred_ttbar, pred_ttbar_mask)\n",
    "true_observable, true_observable_mask = ttbar_mass(true_ttbar, true_ttbar_mask)\n",
    "detector_observable, detector_observable_mask = ttbar_mass(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "simple_hist(\n",
    "    true_observable,\n",
    "    pred_observable.T,\n",
    "    detector_observable,\n",
    "    [\n",
    "        true_observable_mask & (true_mask.sum(-1) <= 5), \n",
    "        true_observable_mask & (true_mask.sum(-1) == 6), \n",
    "        true_observable_mask & (true_mask.sum(-1) >= 7)\n",
    "    ],\n",
    "    [\n",
    "        pred_observable_mask.T & (pred_mask.sum(-1) <= 5), \n",
    "        pred_observable_mask.T & (pred_mask.sum(-1) == 6), \n",
    "        pred_observable_mask.T & (pred_mask.sum(-1) >= 7),\n",
    "    ],\n",
    "    [\n",
    "        detector_observable_mask & (detector_mask.sum(-1) <= 5), \n",
    "        detector_observable_mask & (detector_mask.sum(-1) == 6), \n",
    "        detector_observable_mask & (detector_mask.sum(-1) >= 7),\n",
    "    ],\n",
    "    log_scale=False,\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS,\n",
    "    xlabel=\"$m^{t\\\\bar{t}}$ [GeV]\",\n",
    "    save=f\"jets_split/ttbar_by_n\",\n",
    "    mask_names=[\"$N_{jets} \\\\leq 4$\", \"$N_{jets} = 5$\", \"$N_{jets} \\\\geq 6$\"],\n",
    "    ranges=(300, 1300),\n",
    "    mask_name_location=[0.25, 0.85],\n",
    "    score=SCORE,\n",
    "    base_width=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455465d-15db-4af6-b4f0-4ef89e4cd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_observable, pred_observable_mask = t_pt(pred_ttbar, pred_ttbar_mask)\n",
    "true_observable, true_observable_mask = t_pt(true_ttbar, true_ttbar_mask)\n",
    "detector_observable, detector_observable_mask = t_pt(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "true_count = true_mask.sum(-1)\n",
    "pred_count = pred_mask.sum(-1)\n",
    "detector_count = detector_mask.sum(-1)\n",
    "\n",
    "true_count = np.concatenate((true_count, true_count), axis=0)\n",
    "pred_count = np.concatenate((pred_count, pred_count), axis=0)\n",
    "detector_count = np.concatenate((detector_count, detector_count), axis=0)\n",
    "\n",
    "simple_hist(\n",
    "    true_observable,\n",
    "    pred_observable.T,\n",
    "    detector_observable,\n",
    "    [\n",
    "        true_observable_mask & (true_count <= 5), \n",
    "        true_observable_mask & (true_count == 6), \n",
    "        true_observable_mask & (true_count >= 7)\n",
    "    ],\n",
    "    [\n",
    "        pred_observable_mask.T & (pred_count <= 5), \n",
    "        pred_observable_mask.T & (pred_count == 6), \n",
    "        pred_observable_mask.T & (pred_count >= 7),\n",
    "    ],\n",
    "    [\n",
    "        detector_observable_mask & (detector_count <= 5), \n",
    "        detector_observable_mask & (detector_count == 6), \n",
    "        detector_observable_mask & (detector_count >= 7),\n",
    "    ],\n",
    "    log_scale=False,\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS,\n",
    "    xlabel=\"$p_\\\\mathrm{T}^\\\\mathrm{top}$ [GeV]\",\n",
    "    save=f\"jets_split/tpt_by_n\",\n",
    "    mask_names=[\"$N_{jets} \\\\leq 4$\", \"$N_{jets} = 5$\", \"$N_{jets} \\\\geq 6$\"],\n",
    "    ranges=(0, 400),\n",
    "    mask_name_location=[0.32, 0.85],\n",
    "    score=SCORE,\n",
    "    base_width=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b3faa-c9c7-4c17-b736-29afcc5a7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_observable, pred_observable_mask = t_pt(pred_ttbar, pred_ttbar_mask)\n",
    "true_observable, true_observable_mask = t_pt(true_ttbar, true_ttbar_mask)\n",
    "detector_observable, detector_observable_mask = t_pt(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "pred_mask_observable, pred_mask_observable_mask = ttbar_mass(pred_ttbar, pred_ttbar_mask)\n",
    "true_mask_observable, true_mask_observable_mask = ttbar_mass(true_ttbar, true_ttbar_mask)\n",
    "detector_mask_observable, detector_mask_observable_mask = ttbar_mass(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "pred_mask_observable = np.concatenate((pred_mask_observable, pred_mask_observable), axis=1).T\n",
    "true_mask_observable = np.concatenate((true_mask_observable, true_mask_observable), axis=0)\n",
    "detector_mask_observable = np.concatenate((detector_mask_observable, detector_mask_observable), axis=0)\n",
    "\n",
    "pred_mask_observable_mask = np.concatenate((pred_mask_observable_mask, pred_mask_observable_mask), axis=1).T\n",
    "true_mask_observable_mask = np.concatenate((true_mask_observable_mask, true_mask_observable_mask), axis=0)\n",
    "detector_mask_observable_mask = np.concatenate((detector_mask_observable_mask, detector_mask_observable_mask), axis=0)\n",
    "\n",
    "pred_mask_observable = pred_mask_observable / 1000\n",
    "true_mask_observable = true_mask_observable / 1000\n",
    "detector_mask_observable = detector_mask_observable / 1000\n",
    "\n",
    "simple_hist(\n",
    "    true_observable,\n",
    "    pred_observable.T,\n",
    "    detector_observable,\n",
    "    [\n",
    "        true_observable_mask & true_mask_observable_mask & (true_mask_observable >= 0.2) & (true_mask_observable <= 0.4), \n",
    "        true_observable_mask & true_mask_observable_mask & (true_mask_observable >= 0.4) & (true_mask_observable <= 0.55), \n",
    "        true_observable_mask & true_mask_observable_mask & (true_mask_observable >= 0.55) & (true_mask_observable <= 0.7), \n",
    "        true_observable_mask & true_mask_observable_mask & (true_mask_observable >= 0.7) & (true_mask_observable <= 1.0), \n",
    "        true_observable_mask & true_mask_observable_mask & (true_mask_observable >= 1.0) & (true_mask_observable <= 2.0), \n",
    "    ],\n",
    "    [\n",
    "        pred_observable_mask.T & pred_mask_observable_mask & (pred_mask_observable >= 0.2) & (pred_mask_observable <= 0.4), \n",
    "        pred_observable_mask.T & pred_mask_observable_mask & (pred_mask_observable >= 0.4) & (pred_mask_observable <= 0.55), \n",
    "        pred_observable_mask.T & pred_mask_observable_mask & (pred_mask_observable >= 0.55) & (pred_mask_observable <= 0.7), \n",
    "        pred_observable_mask.T & pred_mask_observable_mask & (pred_mask_observable >= 0.7) & (pred_mask_observable <= 1.0), \n",
    "        pred_observable_mask.T & pred_mask_observable_mask & (pred_mask_observable >= 1.0) & (pred_mask_observable <= 2.0), \n",
    "    \n",
    "    ],\n",
    "    [\n",
    "        detector_observable_mask & detector_mask_observable_mask & (detector_mask_observable >= 0.2) & (detector_mask_observable <= 0.4), \n",
    "        detector_observable_mask & detector_mask_observable_mask & (detector_mask_observable >= 0.4) & (detector_mask_observable <= 0.55), \n",
    "        detector_observable_mask & detector_mask_observable_mask & (detector_mask_observable >= 0.55) & (detector_mask_observable <= 0.7), \n",
    "        detector_observable_mask & detector_mask_observable_mask & (detector_mask_observable >= 0.7) & (detector_mask_observable <= 1.0), \n",
    "        detector_observable_mask & detector_mask_observable_mask & (detector_mask_observable >= 1.0) & (detector_mask_observable <= 2.0), \n",
    "    \n",
    "    ],\n",
    "    log_scale=False,\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS,\n",
    "    xlabel=\"$p_\\\\mathrm{T}^\\\\mathrm{top}$ [GeV]\",\n",
    "    save=f\"jets_split/tpt_by_ttmass\",\n",
    "    mask_names=[\n",
    "        \"$m^{t \\\\bar{t}} : [0.2, 0.4]$\",\n",
    "        \"$m^{t \\\\bar{t}} : [0.4, 0.55]$\",\n",
    "        \"$m^{t \\\\bar{t}} : [0.55, 0.7]$\",\n",
    "        \"$m^{t \\\\bar{t}} : [0.7, 1.0]$\",\n",
    "        \"$m^{t \\\\bar{t}} : [1.0, 2.0]$\"\n",
    "    ],\n",
    "    ranges=(0, 500),\n",
    "    mask_name_location=[0.5, 0.32],\n",
    "    score=SCORE,\n",
    "    base_width=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e9515-080c-4cff-9e97-a44123c8889c",
   "metadata": {},
   "source": [
    "## Event Observables\n",
    "\n",
    "Event-level observables and their plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "822e6b64-a407-4db5-9147-94688e3c48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"$\\\\Delta_\\\\phi Between Leading Jets$\"\n",
    "def delta_angle(vectors, mask):\n",
    "    delta = vectors[..., 0].deltaangle(vectors[..., 1])\n",
    "    return delta, mask[..., :2].all(-1)\n",
    "\n",
    "NAME = \"H_t [GeV]\"\n",
    "def sum_pt(vectors, mask):\n",
    "    return np.sum(vectors.pt, where=mask, axis=-1), mask.any(-1)\n",
    "\n",
    "event_observables = [delta_angle, sum_pt]\n",
    "event_observables = {func.__name__: func for func in event_observables}\n",
    "\n",
    "EVENT_OBSERVABLES = [\n",
    "    (\"delta_angle\", \"$\\\\Delta_\\\\phi$ Between Leading Jets\", None, None),\n",
    "    (\"sum_pt\", \"$H_\\\\mathrm{T}$ [GeV]\", 0, 1000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3089af-4c61-428a-9437-1da2df325f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, fancy_name, xmin, xmax in EVENT_OBSERVABLES:\n",
    "    observable = event_observables[name]\n",
    "    \n",
    "    pred_observable, pred_observable_mask = observable(pred_ttbar, pred_ttbar_mask)\n",
    "    true_observable, true_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    detector_observable, detector_observable_mask = observable(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "    ranges = (xmin, xmax) if xmin is not None else None\n",
    "    \n",
    "    simple_hist(\n",
    "        true_observable,\n",
    "        pred_observable.T,\n",
    "        detector_observable,\n",
    "        true_observable_mask,\n",
    "        pred_observable_mask.T,\n",
    "        detector_observable_mask,\n",
    "        log_scale=False,\n",
    "        scatter_yrange=(-0.5, 0.5), \n",
    "        bins=BINS,\n",
    "        xlabel=fancy_name,\n",
    "        save=f\"observables/{name}\",\n",
    "        ranges=ranges,\n",
    "        score=SCORE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07eb6b-07cc-47fe-a834-8e98ee2ed636",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_observable, pred_observable_mask = sum_pt(pred_ttbar, pred_ttbar_mask)\n",
    "true_observable, true_observable_mask = sum_pt(true_ttbar, true_ttbar_mask)\n",
    "detector_observable, detector_observable_mask = sum_pt(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "simple_hist(\n",
    "    true_observable,\n",
    "    pred_observable.T,\n",
    "    detector_observable,\n",
    "    [\n",
    "        true_observable_mask & (true_mask.sum(-1) <= 5), \n",
    "        true_observable_mask & (true_mask.sum(-1) == 6), \n",
    "        true_observable_mask & (true_mask.sum(-1) >= 7)\n",
    "    ],\n",
    "    [\n",
    "        pred_observable_mask.T & (pred_mask.sum(-1) <= 5), \n",
    "        pred_observable_mask.T & (pred_mask.sum(-1) == 6), \n",
    "        pred_observable_mask.T & (pred_mask.sum(-1) >= 7),\n",
    "    ],\n",
    "    [\n",
    "        detector_observable_mask & (detector_mask.sum(-1) <= 5), \n",
    "        detector_observable_mask & (detector_mask.sum(-1) == 6), \n",
    "        detector_observable_mask & (detector_mask.sum(-1) >= 7),\n",
    "    ],\n",
    "    log_scale=False,\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS,\n",
    "    xlabel=\"$H_\\\\mathrm{T}$ [GeV]\",\n",
    "    save=f\"jets_split/ht_by_n\",\n",
    "    mask_names=[\"$N_{jets} \\\\leq 4$\", \"$N_{jets} = 5$\", \"$N_{jets} \\\\geq 6$\"],\n",
    "    ranges=(0, 800),\n",
    "    hist_yrange=(0, 7e-3),\n",
    "    mask_name_location=[0.20, 0.85],\n",
    "    score=SCORE,\n",
    "    base_width=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41f08f-339f-437a-bbb6-51d0bbfc968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_observable, pred_observable_mask = sum_pt(pred_ttbar, pred_ttbar_mask)\n",
    "true_observable, true_observable_mask = sum_pt(true_ttbar, true_ttbar_mask)\n",
    "detector_observable, detector_observable_mask = sum_pt(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "delta = np.abs(pred_mask.sum(-1) - detector_mask.sum(-1)[:, None])\n",
    "delta = np.median(delta, axis=1)\n",
    "\n",
    "simple_hist(\n",
    "    true_observable,\n",
    "    pred_observable.T,\n",
    "    detector_observable,\n",
    "    [\n",
    "        true_observable_mask & (delta == 0), \n",
    "        true_observable_mask & (delta <= 1) & (delta > 0),\n",
    "        true_observable_mask & (delta >= 1.5)\n",
    "    ],\n",
    "    [\n",
    "        pred_observable_mask.T & (delta[:, None] == 0), \n",
    "        pred_observable_mask.T & (delta[:, None] <= 1) & (delta[:, None] > 0),\n",
    "        pred_observable_mask.T & (delta[:, None] >= 1.5)\n",
    "    ],\n",
    "    [\n",
    "        detector_observable_mask & (delta == 0), \n",
    "        detector_observable_mask & (delta <= 1) & (delta > 0),\n",
    "        detector_observable_mask & (delta >= 1.5)\n",
    "    ],\n",
    "\n",
    "    log_scale=False,\n",
    "    scatter_yrange=(-1, 1),\n",
    "    bins=BINS // 2,\n",
    "    xlabel=\"$H_\\\\mathrm{T}$ [GeV]\",\n",
    "    save=f\"jets_split/ht_by_delta_n\",\n",
    "    mask_names=[\"$|\\\\Delta N| = 0$\", \"$|\\\\Delta N| = 1$\", \"$|\\\\Delta N| \\geq 2$\"],\n",
    "    ranges=(0, 800),\n",
    "    hist_yrange=(0, 7e-3),\n",
    "    mask_name_location=[0.10, 0.85],\n",
    "    score=SCORE,\n",
    "    base_width=5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fc38e-af22-4e72-a03d-dafd5202092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_pt_sum(vectors, mask, met):\n",
    "    vectors = vector.arr({\n",
    "        \"pt\": vectors.pt * mask,\n",
    "        \"eta\": vectors.eta * mask,\n",
    "        \"phi\": vectors.phi * mask,\n",
    "        \"mass\": vectors.mass * mask\n",
    "    })\n",
    "\n",
    "    return vectors.sum(-1).pt - met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a70981-0b74-49bf-b6c1-13294fc8f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_hist(\n",
    "    vector_pt_sum(all_true_kinematics, true_mask, true_met),\n",
    "    vector_pt_sum(all_pred_kinematics, pred_mask, pred_met),\n",
    "    vector_pt_sum(all_detector_kinematics, detector_mask, detector_met),\n",
    "    true_mask.any(-1),\n",
    "    pred_mask.any(-1),\n",
    "    detector_mask.any(-1),\n",
    "    log_scale=False,\n",
    "    scatter_yrange=(-0.5, 0.5),\n",
    "    bins=BINS,\n",
    "    xlabel=\"Vector Sum $p_\\mathrm{T} - E_\\mathrm{T}^\\mathrm{miss}$ [GeV]\",\n",
    "    save=f\"observables/vector_sum\",\n",
    "    ranges=(-100, 100),\n",
    "    base_width=6,\n",
    "    fontsize=\"x-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc526a0",
   "metadata": {},
   "source": [
    "## Multiplicity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fecbaa8-91c7-4733-9934-55b7c120feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bins = 20\n",
    "min_bins = 12\n",
    "x = np.arange(max_bins + 1)\n",
    "x = (x[1:] + x[:-1]) / 2\n",
    "x = x[:min_bins]\n",
    "true_bins = np.bincount(true_mask.sum(-1), minlength=max_bins)[1:min_bins]\n",
    "detector_bins = np.bincount(detector_mask.sum(-1), minlength=max_bins)[1:min_bins]\n",
    "pred_bins = np.stack([\n",
    "    np.bincount(pred, minlength=max_bins)[1:min_bins]\n",
    "    for pred in pred_mask.sum(-1).T\n",
    "])\n",
    "\n",
    "true_bins = true_bins / true_bins.sum()\n",
    "detector_bins = detector_bins / detector_bins.sum()\n",
    "pred_bins = pred_bins / pred_bins.sum(-1, keepdims=True)\n",
    "\n",
    "x = x[1:] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f021c-03bd-4e68-bcda-aa03a7ab6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, height_ratios=(1.8, 1), sharex=True, figsize=(6, 6))\n",
    "\n",
    "if COMPARE_DATASET is not None:\n",
    "    comp = np.load(f\"{COMPARE_FOLDER}/observables/multiplicity.npz\")\n",
    "    \n",
    "    ax1.step(x, pred_bins.mean(0), label=\"EFT Unfolded\", linestyle=\"-\", color='orange', linewidth=2)\n",
    "    ax1.step(x, true_bins, label=\"EFT Truth\", linestyle=\"--\", color='m', linewidth=2)\n",
    "    ax1.step(x, detector_bins, label=\"EFT Detector\", linestyle=\":\", color='g', linewidth=2)\n",
    "    \n",
    "    ax1.fill_between(x, pred_bins.min(0), pred_bins.max(0), color='orange', step=\"pre\", alpha=0.2)\n",
    "    ax1.step(x, pred_bins.max(0), linestyle=\"--\", alpha=0.4, color='orange', linewidth=2)\n",
    "    ax1.step(x, pred_bins.min(0), linestyle=\"--\", alpha=0.4, color='orange', linewidth=2)\n",
    "    \n",
    "    ax1.step(x, comp[\"pred_bins\"].mean(0), label=\"SM Unfolded\", linestyle=\"-\", color='r', linewidth=2)\n",
    "    ax1.step(x, comp[\"true_bins\"], label=\"SM Truth\", linestyle=\"--\", color='b', linewidth=2)\n",
    "\n",
    "    ax2.step(x, np.log(comp[\"pred_bins\"].mean(0) / true_bins), color='r', linestyle='-', linewidth=3)\n",
    "    ax2.step(x, np.log(pred_bins.mean(0) / true_bins), color='orange', linestyle='-', linewidth=3)\n",
    "    ax2.fill_between(x, np.log(pred_bins.min(0) / true_bins), np.log(pred_bins.max(0) / true_bins), step=\"pre\", color='orange', alpha=0.2)\n",
    "    ax2.step(x, np.log(pred_bins.min(0) / true_bins), color='orange', linestyle='--', alpha=0.4, linewidth=2)\n",
    "    ax2.step(x, np.log(pred_bins.max(0) / true_bins), color='orange', linestyle='--', alpha=0.4, linewidth=2)\n",
    "    ax2.step(x, np.log(detector_bins / true_bins), color='g', linestyle=\":\", linewidth=3)\n",
    "\n",
    "else:\n",
    "    ax1.step(x, pred_bins.mean(0), label=\"Unfolded\", linestyle=\"-\", color='r', linewidth=2)\n",
    "    ax1.fill_between(x, pred_bins.min(0), pred_bins.max(0), color='r', step=\"pre\", alpha=0.2)\n",
    "    ax1.step(x, pred_bins.max(0), linestyle=\"--\", alpha=0.4, color='r', linewidth=2)\n",
    "    ax1.step(x, pred_bins.min(0), linestyle=\"--\", alpha=0.4, color='r', linewidth=2)\n",
    "    ax1.step(x, true_bins, label=\"SM Truth\", linestyle=\"--\", color='b', linewidth=2)\n",
    "    ax1.step(x, detector_bins, label=\"SM Detector\", linestyle=\":\", color='g', linewidth=2)\n",
    "    \n",
    "    ax2.step(x, np.log(pred_bins.mean(0) / true_bins), color='r', linestyle='-', linewidth=3)\n",
    "    ax2.fill_between(x, np.log(pred_bins.min(0) / true_bins), np.log(pred_bins.max(0) / true_bins), step=\"pre\", color='r', alpha=0.2)\n",
    "    ax2.step(x, np.log(pred_bins.min(0) / true_bins), color='r', linestyle='--', alpha=0.4, linewidth=2)\n",
    "    ax2.step(x, np.log(pred_bins.max(0) / true_bins), color='r', linestyle='--', alpha=0.4, linewidth=2)\n",
    "    ax2.step(x, np.log(detector_bins / true_bins), color='g', linestyle=\":\", linewidth=3)\n",
    "\n",
    "ax2.hlines(0.0, 0, min_bins, linestyle='--', colors='m')\n",
    "\n",
    "ax1.set_ylabel(\"Density\")\n",
    "ax2.set_ylabel(\"Log Ratio\")\n",
    "\n",
    "ax1.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "ax1.ticklabel_format(style=\"scientific\", scilimits=(0, 0), useMathText=True, axis=\"y\")\n",
    "ax1.ticklabel_format(useMathText=True, axis=\"x\")\n",
    "ax2.ticklabel_format(useMathText=True)\n",
    "yfmt = ScalarFormatterForceFormat()\n",
    "yfmt.set_powerlimits((0,0))\n",
    "ax1.yaxis.set_major_formatter(yfmt)\n",
    "ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:1.1f}'))\n",
    "ax1.set_ylim(0, ax1.get_ylim()[1])\n",
    "\n",
    "fig.align_ylabels([ax1, ax2])\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "ax2.set_xticks(np.arange(min_bins + 1));\n",
    "plt.xlabel(\"$N_\\mathrm{Jets}$\")\n",
    "plt.xlim(3, 10)\n",
    "ax1.set_ylim(0, 0.6)\n",
    "ax2.set_ylim(-0.5, 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.0, right=0.96)\n",
    "        \n",
    "\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/observables/multiplicity.png\", dpi=300)\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/observables/multiplicity.pdf\")\n",
    "np.savez(f\"{OUTPUT_FOLDER}/observables/multiplicity.npz\", x=x, true_bins=true_bins, pred_bins=pred_bins, detector_bins=detector_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5b38493-a270-4265-9b5c-ff046d5cbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "bins = (bins[1:] + bins[:-1]) / 2\n",
    "\n",
    "dp, x = np.histogram(\n",
    "    (pred_mask.any(-1) * true_mask.any(-1)[:, None] * (pred_mask.sum(-1) - true_mask.sum(-1)[:pred_mask.shape[0], None])).ravel(),\n",
    "    bins=bins, \n",
    "    range=(-3, 3), \n",
    "    density=True\n",
    ")\n",
    "\n",
    "dd, x = np.histogram(\n",
    "    (pred_mask.any(-1) * detector_mask.any(-1)[:, None] * (pred_mask.sum(-1) - detector_mask.sum(-1)[:pred_mask.shape[0], None])).ravel(),\n",
    "    bins=bins, \n",
    "    range=(-3, 3), \n",
    "    density=True\n",
    ")\n",
    "\n",
    "dt, x = np.histogram(true_mask.any(-1) * detector_mask.any(-1) * (detector_mask.sum(-1) - true_mask.sum(-1)), bins=bins, range=(-3, 3), density=True)\n",
    "\n",
    "x = (x[1:] + x[:-1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e198de-8a0d-4d94-8f22-c62e5b110af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = np.stack((x / 100, dp, dd, dt))\n",
    "ns = [\"$\\Delta N_{Jets}$\", \"$N_{Unfolded} - N_{Particle}$\", \"$N_{Unfolded} - N_{Detector}$\", \"$N_{Detector} - N_{Particle}$\"]\n",
    "for n, v in zip(ns, vs):\n",
    "    print(n + \" & \" + \" & \".join(map(lambda s: f\"${100 * s:02.0f}$\", v)) + \" \\\\\\\\ \\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d830e-e49f-4438-ad49-af70576b40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, dp, label=\"$N_{Unfolded} - N_{Particle}$\", linewidth=3)\n",
    "plt.plot(x, dd, label=\"$N_{Unfolded} - N_{Detector}$\", linewidth=3, linestyle=\"--\")\n",
    "plt.plot(x, dt, label=\"$N_{Detector} - N_{Particle}$\", linewidth=3, linestyle=\":\")\n",
    "plt.xlabel(\"$\\\\Delta N$\")\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(0.0, 0.0, 1.03, 1.04))\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/observables/multiplicity_delta.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb392f4e-2f6f-4e6c-981b-43c71a673b02",
   "metadata": {},
   "source": [
    "## Corner Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539ad93-81ef-4cb2-8b26-28d71c594e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ttbar, true_ttbar_mask = auto_match_b_quark(all_true_kinematics, true_types, true_mask, true_met, true_met_phi, pre_mask=truth_event_pre_mask, hard_mask=True)\n",
    "detector_ttbar, detector_ttbar_mask = auto_match_b_quark(all_detector_kinematics, detector_types, detector_mask, detector_met, detector_met_phi, hard_mask=True)\n",
    "\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/corner\", exist_ok=True)\n",
    "\n",
    "OBSERVABLES = [\n",
    "    (\"hadronic_top_mass\", \"$m^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", 50, 350, None, None),\n",
    "    (\"pt_out_had\", \"$p^{\\\\mathrm{top},\\\\mathrm{had}}_{\\\\mathrm{Out}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"thad_pt\", \"$p_T^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"thad_eta\", \"$\\\\eta^{\\\\mathrm{top},\\\\mathrm{had}}$\", -2.5, 2.5, -0.5, 0.5),\n",
    "    (\"thad_energy\", \"$E^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"thad_y\", \"$y^{\\\\mathrm{top},\\\\mathrm{had}}$\", None, None, -0.5, 0.5),\n",
    "]\n",
    "\n",
    "\n",
    "total_pred_observable_mask = pred_ttbar_mask[0].all(-1)\n",
    "pred_observables = []\n",
    "pred_observable_names = []\n",
    "pred_observable_ranges = []\n",
    "\n",
    "for name, fancy_name, xmin, xmax, rmin, rmax in tqdm(OBSERVABLES):\n",
    "    observable = observables[name]\n",
    "\n",
    "    pred_observable, pred_observable_mask = observable(pred_ttbar[0:1], pred_ttbar_mask[0:1])\n",
    "    pred_observable = pred_observable.ravel()[total_pred_observable_mask]\n",
    "    if xmin is None:\n",
    "        xmin = np.percentile(pred_observable, 0.1)\n",
    "        xmax = np.percentile(pred_observable, 100.0 - 0.1)\n",
    "        \n",
    "    # pred_observable = pred_observable.ravel()[pred_observable_mask.ravel()]\n",
    "    # true_observable, true_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    # detector_observable, detector_observable_mask = observable(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "    pred_observables.append(pred_observable)\n",
    "    pred_observable_names.append(fancy_name)\n",
    "    pred_observable_ranges.append((xmin, xmax))\n",
    "\n",
    "pred_observables = np.stack(pred_observables, axis=-1)\n",
    "\n",
    "fig = corner.corner(\n",
    "    pred_observables,\n",
    "    labels=pred_observable_names,\n",
    "    range=pred_observable_ranges,\n",
    "    # fig=fig,\n",
    "    # quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 20}\n",
    ");\n",
    "\n",
    "fig.set_figwidth(pred_observables.shape[1] * 4)\n",
    "fig.set_figheight(pred_observables.shape[1] * 4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/corner/pred_had.pdf\")\n",
    "\n",
    "\n",
    "total_pred_observable_mask = true_ttbar_mask.all(-1)\n",
    "pred_observables = []\n",
    "pred_observable_names = []\n",
    "pred_observable_ranges = []\n",
    "\n",
    "for name, fancy_name, xmin, xmax, rmin, rmax in tqdm(OBSERVABLES):\n",
    "    observable = observables[name]\n",
    "\n",
    "    pred_observable, pred_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    pred_observable = pred_observable.ravel()[total_pred_observable_mask]\n",
    "    if xmin is None:\n",
    "        xmin = np.percentile(pred_observable, 0.1)\n",
    "        xmax = np.percentile(pred_observable, 100.0 - 0.1)\n",
    "        \n",
    "    # pred_observable = pred_observable.ravel()[pred_observable_mask.ravel()]\n",
    "    # true_observable, true_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    # detector_observable, detector_observable_mask = observable(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "    pred_observables.append(pred_observable)\n",
    "    pred_observable_names.append(fancy_name)\n",
    "    pred_observable_ranges.append((xmin, xmax))\n",
    "\n",
    "pred_observables = np.stack(pred_observables, axis=-1)\n",
    "\n",
    "fig = corner.corner(\n",
    "    pred_observables,\n",
    "    labels=pred_observable_names,\n",
    "    range=pred_observable_ranges,\n",
    "    # fig=fig,\n",
    "    # quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 20}\n",
    ");\n",
    "\n",
    "fig.set_figwidth(pred_observables.shape[1] * 4)\n",
    "fig.set_figheight(pred_observables.shape[1] * 4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/corner/true_had.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbceb53-1e87-4f83-a246-c8299f126ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ttbar, true_ttbar_mask = auto_match_b_quark(all_true_kinematics, true_types, true_mask, true_met, true_met_phi, pre_mask=truth_event_pre_mask, hard_mask=True)\n",
    "detector_ttbar, detector_ttbar_mask = auto_match_b_quark(all_detector_kinematics, detector_types, detector_mask, detector_met, detector_met_phi, hard_mask=True)\n",
    "\n",
    "os.makedirs(f\"{OUTPUT_FOLDER}/corner\", exist_ok=True)\n",
    "\n",
    "OBSERVABLES = [\n",
    "    (\"leptonic_top_mass\", \"$m^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", 50, 350, None, None),\n",
    "    (\"pt_out_lep\", \"$p^{\\\\mathrm{top},\\\\mathrm{had}}_{\\\\mathrm{Out}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"tlep_pt\", \"$p_T^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"tlep_eta\", \"$\\\\eta^{\\\\mathrm{top},\\\\mathrm{had}}$\", -2.5, 2.5, -0.5, 0.5),\n",
    "    (\"tlep_energy\", \"$E^{\\\\mathrm{top},\\\\mathrm{had}}$ [GeV]\", None, None, -0.5, 0.5),\n",
    "    (\"tlep_y\", \"$y^{\\\\mathrm{top},\\\\mathrm{had}}$\", None, None, -0.5, 0.5),\n",
    "]\n",
    "\n",
    "\n",
    "total_pred_observable_mask = pred_ttbar_mask[0].all(-1)\n",
    "pred_observables = []\n",
    "pred_observable_names = []\n",
    "pred_observable_ranges = []\n",
    "\n",
    "for name, fancy_name, xmin, xmax, rmin, rmax in tqdm(OBSERVABLES):\n",
    "    observable = observables[name]\n",
    "\n",
    "    pred_observable, pred_observable_mask = observable(pred_ttbar[0:1], pred_ttbar_mask[0:1])\n",
    "    pred_observable = pred_observable.ravel()[total_pred_observable_mask]\n",
    "    if xmin is None:\n",
    "        xmin = np.percentile(pred_observable, 0.1)\n",
    "        xmax = np.percentile(pred_observable, 100.0 - 0.1)\n",
    "        \n",
    "    # pred_observable = pred_observable.ravel()[pred_observable_mask.ravel()]\n",
    "    # true_observable, true_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    # detector_observable, detector_observable_mask = observable(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "    pred_observables.append(pred_observable)\n",
    "    pred_observable_names.append(fancy_name)\n",
    "    pred_observable_ranges.append((xmin, xmax))\n",
    "\n",
    "pred_observables = np.stack(pred_observables, axis=-1)\n",
    "\n",
    "fig = corner.corner(\n",
    "    pred_observables,\n",
    "    labels=pred_observable_names,\n",
    "    range=pred_observable_ranges,\n",
    "    # fig=fig,\n",
    "    # quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 20}\n",
    ");\n",
    "\n",
    "fig.set_figwidth(pred_observables.shape[1] * 4)\n",
    "fig.set_figheight(pred_observables.shape[1] * 4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/corner/pred_lep.pdf\")\n",
    "\n",
    "\n",
    "total_pred_observable_mask = true_ttbar_mask.all(-1)\n",
    "pred_observables = []\n",
    "pred_observable_names = []\n",
    "pred_observable_ranges = []\n",
    "\n",
    "for name, fancy_name, xmin, xmax, rmin, rmax in tqdm(OBSERVABLES):\n",
    "    observable = observables[name]\n",
    "\n",
    "    pred_observable, pred_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    pred_observable = pred_observable.ravel()[total_pred_observable_mask]\n",
    "    if xmin is None:\n",
    "        xmin = np.percentile(pred_observable, 0.1)\n",
    "        xmax = np.percentile(pred_observable, 100.0 - 0.1)\n",
    "        \n",
    "    # pred_observable = pred_observable.ravel()[pred_observable_mask.ravel()]\n",
    "    # true_observable, true_observable_mask = observable(true_ttbar, true_ttbar_mask)\n",
    "    # detector_observable, detector_observable_mask = observable(detector_ttbar, detector_ttbar_mask)\n",
    "\n",
    "    pred_observables.append(pred_observable)\n",
    "    pred_observable_names.append(fancy_name)\n",
    "    pred_observable_ranges.append((xmin, xmax))\n",
    "\n",
    "pred_observables = np.stack(pred_observables, axis=-1)\n",
    "\n",
    "fig = corner.corner(\n",
    "    pred_observables,\n",
    "    labels=pred_observable_names,\n",
    "    range=pred_observable_ranges,\n",
    "    # fig=fig,\n",
    "    # quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 20}\n",
    ");\n",
    "\n",
    "fig.set_figwidth(pred_observables.shape[1] * 4)\n",
    "fig.set_figheight(pred_observables.shape[1] * 4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_FOLDER}/corner/true_lep.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
